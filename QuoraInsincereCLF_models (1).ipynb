{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_3I5Lf8A_nSt",
    "outputId": "21607e4d-6eb5-4c06-86e9-8fc658cf7475"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd, numpy as np\n",
    "from numpy.testing import assert_allclose\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "from textblob import TextBlob\n",
    "#from spacy_langdetect import LanguageDetector\n",
    "#from langdetect import detect\n",
    "#import swifter\n",
    "import datetime\n",
    "import spacy\n",
    "import os\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.manifold import TSNE\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from os import path\n",
    "from PIL import Image\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers import Bidirectional, GlobalMaxPooling1D,Conv1D,SpatialDropout1D,Concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers import CuDNNGRU,CuDNNLSTM\n",
    "from keras.layers import GlobalAveragePooling1D\n",
    "from tensorflow.keras import layers\n",
    "from keras.layers import Flatten\n",
    "from tensorflow.keras import regularizers\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0f_P8sMpbnMF",
    "outputId": "8cc7a1a0-dba9-4b6a-eb24-96f8ba958235"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q_JIZagLMBjj",
    "outputId": "b32713de-ff83-4339-f9a6-cd2ea57b4ee5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Kaggle\n"
     ]
    }
   ],
   "source": [
    "%cd  /content/drive/MyDrive/Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "id": "tQ9VKCsKMQf7",
    "outputId": "bdad329e-1c86-4413-a583-7b65338ccbb5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-e3f36a58-a3d7-44c4-8a14-25f400ef4c2c\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>question_len</th>\n",
       "      <th>num_of_words</th>\n",
       "      <th>num_of_sentences</th>\n",
       "      <th>unique_words</th>\n",
       "      <th>stop_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how did quebec nationalists see their province...</td>\n",
       "      <td>72</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>do you have an adopted dog how would you encou...</td>\n",
       "      <td>81</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>why does velocity affect time does velocity af...</td>\n",
       "      <td>67</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how did otto von guericke used the magdeburg h...</td>\n",
       "      <td>57</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>can i convert montra helicon d to a mountain b...</td>\n",
       "      <td>77</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>is gaza slowly becoming auschwitz dachau or tr...</td>\n",
       "      <td>72</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>why does quora automatically ban conservative ...</td>\n",
       "      <td>113</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>is it crazy if i wash or wipe my groceries off...</td>\n",
       "      <td>69</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>is there such a thing as dressing moderately a...</td>\n",
       "      <td>102</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>is it just me or have you ever been in this ph...</td>\n",
       "      <td>246</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e3f36a58-a3d7-44c4-8a14-25f400ef4c2c')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-e3f36a58-a3d7-44c4-8a14-25f400ef4c2c button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-e3f36a58-a3d7-44c4-8a14-25f400ef4c2c');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                            question  question_len  \\\n",
       "0  how did quebec nationalists see their province...            72   \n",
       "1  do you have an adopted dog how would you encou...            81   \n",
       "2  why does velocity affect time does velocity af...            67   \n",
       "3  how did otto von guericke used the magdeburg h...            57   \n",
       "4  can i convert montra helicon d to a mountain b...            77   \n",
       "5  is gaza slowly becoming auschwitz dachau or tr...            72   \n",
       "6  why does quora automatically ban conservative ...           113   \n",
       "7  is it crazy if i wash or wipe my groceries off...            69   \n",
       "8  is there such a thing as dressing moderately a...           102   \n",
       "9  is it just me or have you ever been in this ph...           246   \n",
       "\n",
       "   num_of_words  num_of_sentences  unique_words  stop_words  \n",
       "0            13                 1            13           6  \n",
       "1            16                 1            15           8  \n",
       "2            10                 2             8           1  \n",
       "3             9                 1             9           2  \n",
       "4            15                 1            15           5  \n",
       "5            10                 1            10           2  \n",
       "6            18                 1            17           9  \n",
       "7            14                 2            14           6  \n",
       "8            18                 1            17          11  \n",
       "9            44                 2            39          23  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading preprocssed data\n",
    "data = pd.read_csv('train_que_preprocessed.csv')\n",
    "train_df = pd.read_csv('train.csv')\n",
    "Y = train_df['target']\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AOhUtalAggyo",
    "outputId": "4dfda58f-02a7-4a51-c17e-ee9bd0a99f36"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FM95VgFONJ1o",
    "outputId": "ca51bb9f-1566-40b6-dfa1-1f26ff59ada8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.of Datapoints in class-0 before split: 1225312\n",
      "No.of Datapoints in class-1 before split: 80810\n",
      "\n",
      "\n",
      "No.of datapoints in training set after the split: 1057958\n",
      "No.of datapoints in cv set after the split: 130613\n",
      "No.of datapoints in test set after the split: 117551\n",
      "\n",
      "\n",
      "No.of datapoints in Train data that belong to class-0: 992502\n",
      "No.of datapoints in Train data that belong to class-1: 65456\n",
      "CPU times: user 6.02 s, sys: 78.2 ms, total: 6.1 s\n",
      "Wall time: 6.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#removing special chars\n",
    "def nospecial(text):\n",
    "\ttext = re.sub(\"[^a-zA-Z\\s]+\", \"\",text)\n",
    "\treturn text\n",
    "\n",
    "data['question'] = data['question'].apply(str).apply(nospecial)\n",
    "\n",
    "# checking no.of data points in each class\n",
    "print('No.of Datapoints in class-0 before split:',Y.value_counts()[0]) \n",
    "print('No.of Datapoints in class-1 before split:',Y.value_counts()[1])\n",
    "\n",
    "#spliting data into train,cv and test sets\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(data, Y, test_size=0.1,stratify = Y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.1,stratify = y_train)\n",
    "\n",
    "print('\\n')\n",
    "print('No.of datapoints in training set after the split:',X_train.shape[0])\n",
    "print('No.of datapoints in cv set after the split:',X_cv.shape[0])\n",
    "print('No.of datapoints in test set after the split:',X_test.shape[0])\n",
    "print('\\n')\n",
    "\n",
    "#print no.of data points that belong to each class after split\n",
    "print('No.of datapoints in Train data that belong to class-0:',(y_train.shape[0]-y_train.sum()))\n",
    "print('No.of datapoints in Train data that belong to class-1:',y_train.sum())\n",
    "\n",
    "#fill null values with empty string\n",
    "X_train.fillna('',inplace = True)\n",
    "X_cv.fillna('',inplace = True)\n",
    "X_test.fillna('',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UvTozcyCmBJL",
    "outputId": "78c78a23-1850-49bd-b18b-a593f520b55f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "398"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YjRl32kIyNkS",
    "outputId": "490523d0-138a-427d-d1f1-6c892af610d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 36s, sys: 6.38 s, total: 5min 42s\n",
      "Wall time: 4min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# truncating sentences that have length greater than the 95%le of length of the questions\n",
    "que_lens = X_train['question'].str.split(' ').apply(len)\n",
    "max_len = int(np.percentile(que_lens,95))\n",
    "\n",
    "\n",
    "max_features = 70000 # max features(words) considered to train the model\n",
    "\n",
    "# since word embedding layer requires words to be indexed, assigning indices to words in the data\n",
    "text_vectorizer = layers.TextVectorization(max_tokens=max_features,output_mode='int',output_sequence_length=max_len)\n",
    "text_vectorizer.adapt(X_train['question']) \n",
    "text_to_index = {v: k for k, v in dict(enumerate(text_vectorizer.get_vocabulary())).items()}\n",
    "\n",
    "def text_2_seq(sentence):\n",
    "  '''converts sentences with words to sentences with indices\n",
    "        params: sentence (text to convert into indices)'''\n",
    "\n",
    "  text_seq = []\n",
    "  for word in sentence.split(' '):\n",
    "    if word in text_to_index.keys():\n",
    "      text_seq.append(text_to_index[word])\n",
    "    else:\n",
    "      text_seq.append(1)\n",
    "  return text_seq\n",
    "\n",
    "train_text_indices = X_train['question'].apply(text_2_seq)\n",
    "test_text_indices = X_test['question'].apply(text_2_seq)\n",
    "cv_text_indices = X_cv['question'].apply(text_2_seq)\n",
    "\n",
    "# padding sequences to length equal to 95%le of sentence lengths\n",
    "cv = pad_sequences(cv_text_indices, maxlen=max_len,padding='post')\n",
    "train = pad_sequences(train_text_indices, maxlen=max_len,padding='post')\n",
    "test = pad_sequences(test_text_indices, maxlen=max_len,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y1I344YKsnVG"
   },
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/code/sudalairajkumar/a-look-at-different-embeddings/notebook\n",
    "\n",
    "# below func creates a embedding file for the words\n",
    "\n",
    "def get_embeddings(file_path):\n",
    "  EMBEDDING_FILE = file_path #path to location where embedding file(glove,paragam...) is located\n",
    "  embed_size = 300 #dimension of word embeddings\n",
    "\n",
    "  embeddings_index = dict() #dictionary to store word embeddings\n",
    "\n",
    "  def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32') #splits words and embeddings from embedding file and returns embedding and word\n",
    "  embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE, encoding=\"utf8\", errors='ignore') if len(o)>100) #add words and embeddings to dictionary\n",
    "\n",
    "  no_wordVec_voc = [] # list of no.of words that are not in the embedding file\n",
    "\n",
    "  #count no.of words that are not in embedding file\n",
    "  for word in text_to_index.keys():\n",
    "    if word not in embeddings_index.keys():\n",
    "      no_wordVec_voc.append(word)\n",
    "\n",
    "  print('No.of words that donot have word vector in glove embeddings:',len(no_wordVec_voc),', below are few words,\\n')\n",
    "\n",
    "  #print few words that are not in embedding file\n",
    "  for word in no_wordVec_voc[2:20]:\n",
    "    print(word)\n",
    "\n",
    "  #calculate mean and std of all embeddings to generate a random normal vector for words that do not have an embedding  vector\n",
    "  all_embs = np.stack(embeddings_index.values())\n",
    "  emb_mean,emb_std = all_embs.mean(), all_embs.std() \n",
    "  embed_size = all_embs.shape[1]\n",
    "\n",
    "  # generate embedding matrix\n",
    "  nb_words = max_features\n",
    "  embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "  for word, i in text_to_index.items():\n",
    "    \n",
    "      embedding_vector = embeddings_index.get(word)\n",
    "      if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "  \n",
    "  return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OSyH5CyMd0Z3",
    "outputId": "f4171cc5-c444-48ad-e903-2480b260f80a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.of words that donot have word vector in glove embeddings: 6411 , below are few words,\n",
      "\n",
      "quorans\n",
      "cryptocurrencies\n",
      "brexit\n",
      "redmi\n",
      "kvpy\n",
      "paytm\n",
      "iiser\n",
      "ethereum\n",
      "iisc\n",
      "jinping\n",
      "viteee\n",
      "iocl\n",
      "nmims\n",
      "coinbase\n",
      "iitians\n",
      "fortnite\n",
      "upes\n",
      "rohingya\n",
      "CPU times: user 2min 8s, sys: 18.9 s, total: 2min 27s\n",
      "Wall time: 2min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# generate glove embeddings matrix\n",
    "glove_embeddings = get_embeddings('/content/drive/MyDrive/Kaggle/glove.840B.300d/glove.840B.300d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5AuV0t1vXTiM",
    "outputId": "d4f22273-3194-44aa-fbaf-138c2201f541"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.of words that donot have word vector in glove embeddings: 2780 , below are few words,\n",
      "\n",
      "quorans\n",
      "cryptocurrencies\n",
      "brexit\n",
      "redmi\n",
      "coinbase\n",
      "oneplus\n",
      "demonetisation\n",
      "bhakts\n",
      "uceed\n",
      "gdpr\n",
      "boruto\n",
      "upwork\n",
      "machedo\n",
      "bnbr\n",
      "dceu\n",
      "adityanath\n",
      "alshamsi\n",
      "zerodha\n",
      "CPU times: user 1min 38s, sys: 10.7 s, total: 1min 48s\n",
      "Wall time: 2min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#generate paragram embeddings\n",
    "paragram_embeddings = get_embeddings('/content/drive/MyDrive/Kaggle/paragram_300_sl999/paragram_300_sl999.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tDQxDNwotTdm"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(test_y, predict_y):\n",
    "    C = confusion_matrix(test_y, predict_y)\n",
    "    print(\"Number of misclassified points \",(len(test_y)-np.trace(C))/len(test_y)*100)\n",
    "    # C = 9,9 matrix, each cell (i,j) represents number of points of class i are predicted class j\n",
    "    \n",
    "    A =(((C.T)/(C.sum(axis=1))).T)\n",
    "    #divid each element of the confusion matrix with the sum of elements in that column\n",
    "    \n",
    "    # C = [[1, 2],\n",
    "    #     [3, 4]]\n",
    "    # C.T = [[1, 3],\n",
    "    #        [2, 4]]\n",
    "    # C.sum(axis = 1)  axis=0 corresonds to columns and axis=1 corresponds to rows in two diamensional array\n",
    "    # C.sum(axix =1) = [[3, 7]]\n",
    "    # ((C.T)/(C.sum(axis=1))) = [[1/3, 3/7]\n",
    "    #                           [2/3, 4/7]]\n",
    "\n",
    "    # ((C.T)/(C.sum(axis=1))).T = [[1/3, 2/3]\n",
    "    #                           [3/7, 4/7]]\n",
    "    # sum of row elements = 1\n",
    "    \n",
    "    B =(C/C.sum(axis=0))\n",
    "    #divid each element of the confusion matrix with the sum of elements in that row\n",
    "    # C = [[1, 2],\n",
    "    #     [3, 4]]\n",
    "    # C.sum(axis = 0)  axis=0 corresonds to columns and axis=1 corresponds to rows in two diamensional array\n",
    "    # C.sum(axix =0) = [[4, 6]]\n",
    "    # (C/C.sum(axis=0)) = [[1/4, 2/6],\n",
    "    #                      [3/4, 4/6]] \n",
    "    \n",
    "    labels = [1,2,3,4,5,6,7,8,9]\n",
    "    cmap=sns.light_palette(\"green\")\n",
    "    # representing A in heatmap format\n",
    "    print(\"-\"*50, \"Confusion matrix\", \"-\"*50)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.heatmap(C, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"-\"*50, \"Precision matrix\", \"-\"*50)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.heatmap(B, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.show()\n",
    "    print(\"Sum of columns in precision matrix\",B.sum(axis=0))\n",
    "    \n",
    "    # representing B in heatmap format\n",
    "    print(\"-\"*50, \"Recall matrix\"    , \"-\"*50)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.heatmap(A, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.show()\n",
    "    print(\"Sum of rows in precision matrix\",A.sum(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vQLvIUyu6R_b"
   },
   "source": [
    "#### Building a model with LSTM and a Dense layer that takes word probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rzogjIl61Z2Z"
   },
   "outputs": [],
   "source": [
    "# Calculate word probs for dense layer inputs\n",
    "\n",
    "#create bag words for sincere questions which are used to calculate the word probs\n",
    "sincere_vectorizer = CountVectorizer(binary = True,vocabulary = text_vectorizer.get_vocabulary())\n",
    "sincere_que = X_train[y_train == 0]['question']\n",
    "sincere_bow = sincere_vectorizer.fit_transform(sincere_que) \n",
    "\n",
    "#create bag words for insincere questions which are used to calculate the word probs\n",
    "insincere_vectorizer = CountVectorizer(binary = True,vocabulary = text_vectorizer.get_vocabulary())\n",
    "insincere_que = X_train[y_train == 1]['question']\n",
    "insincere_bow = insincere_vectorizer.fit_transform(insincere_que) \n",
    "\n",
    "# below code generate the count of each word occured in the sincere questions corpus. from the above generated BOW matrix, sum along the columns returns count of\n",
    "# each word in the corpus\n",
    "sincere_bow = pd.DataFrame(sincere_bow.sum(axis = 0).A1,index = sincere_vectorizer.vocabulary_)\n",
    "\n",
    "# below code generate the count of each word occured in the insincere questions corpus. from the above generated BOW matrix, sum along the columns returns count of\n",
    "# each word in the corpus\n",
    "insincere_bow = pd.DataFrame(insincere_bow.sum(axis = 0).A1,index = sincere_vectorizer.vocabulary_)\n",
    "\n",
    "sincere_probs = {} #saves word probs of each word in sincere question corpus\n",
    "insincere_probs = {} #saves word probs of each word in insincere question corpus\n",
    "\n",
    "#calculate word probs\n",
    "for word in sincere_vectorizer.vocabulary_.keys():\n",
    "  sincere_probs[word] = sincere_bow.loc[word].values[0] / sincere_que.shape[0]\n",
    "  insincere_probs[word] = insincere_bow.loc[word].values[0] / insincere_que.shape[0]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2_5UYfzUrBvu",
    "outputId": "7635fb80-f204-4915-c68f-7303a7b0a68b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del sincere_vectorizer,sincere_que,sincere_bow,insincere_vectorizer,insincere_que,insincere_bow\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aSWa59uX1Zqx"
   },
   "outputs": [],
   "source": [
    "# assign word probs to each question\n",
    "\n",
    "def get_probs_df(que):\n",
    "  '''generates an array with word probs for each class of a question'''    \n",
    "  word_probs = [] # list word probs for each class if word is in top 70000 words else 0\n",
    "  for word in que.split(' '):\n",
    "      if sincere_probs.get(word) is not None: \n",
    "        word_probs.append(sincere_probs[word])\n",
    "        word_probs.append(insincere_probs[word])\n",
    "      else:\n",
    "          word_probs.append(0)\n",
    "          word_probs.append(0)\n",
    "\n",
    "    # pad or truncate the arrays to make all the prob arrays of same size\n",
    "  if len(word_probs) > max_len*2:\n",
    "      word_probs = word_probs[:max_len*2]\n",
    "  elif len(word_probs) < max_len*2:\n",
    "      ext = [0]*(max_len*2 - len(word_probs))\n",
    "      word_probs.extend(ext)\n",
    "\n",
    "  return np.array(word_probs)\n",
    "\n",
    "train_probs = X_train['question'].apply(get_probs_df)\n",
    "test_probs = X_test['question'].apply(get_probs_df)\n",
    "cv_probs = X_cv['question'].apply(get_probs_df)\n",
    "\n",
    "cv_probs = np.stack(cv_probs.values)\n",
    "train_probs = np.stack(train_probs.values)\n",
    "test_probs = np.stack(test_probs.values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zxjb7TGuz6jL",
    "outputId": "351109da-45e6-4fc3-d7cd-4e80ed7eeaf8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1057958, 59)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# standardizing the statistical features \n",
    "train_stat_feats = X_train.drop(['question'],axis = 1)\n",
    "cv_stat_feats = X_cv.drop(['question'],axis = 1)\n",
    "test_stat_feats = X_test.drop(['question'],axis = 1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_stat_feats) \n",
    "\n",
    "train_stat_feats_norm = scaler.transform(train_stat_feats)\n",
    "cv_stat_feats_norm = scaler.transform(cv_stat_feats)\n",
    "test_stat_feats_norm = scaler.transform(test_stat_feats)\n",
    "\n",
    "train_stats_merge = np.concatenate((train_stat_feats_norm,train_probs),axis = 1)\n",
    "cv_stats_merge = np.concatenate((cv_stat_feats_norm,cv_probs),axis = 1)\n",
    "test_stats_merge = np.concatenate((test_stat_feats_norm,test_probs),axis = 1)\n",
    "\n",
    "print(train_stats_merge.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74mFD7sp9K0C"
   },
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4BZY_VFiKymg"
   },
   "outputs": [],
   "source": [
    "#defining the model\n",
    "\n",
    "dense_ip = train_stats_merge.shape[1] # input shape of the dense layer\n",
    "\n",
    "def get_naive_model4(rate,embeddings = glove_embeddings):\n",
    "  \n",
    "  lstm_inputs = Input(shape = (max_len,),name = 'lstm_inputs')\n",
    "  dense_inputs = Input(shape = (dense_ip,),name = 'dense_inputs')\n",
    "  \n",
    "  embeddings = Embedding(input_dim = text_vectorizer.vocabulary_size(), output_dim=300,weights=[embeddings],trainable = False,)(lstm_inputs)\n",
    "  x = SpatialDropout1D(rate)(embeddings)\n",
    "  x = Bidirectional(CuDNNLSTM(256, return_sequences=True,name='lstm_layer'))(x)\n",
    "  x = Conv1D(126,2)(x)\n",
    "  x = GlobalMaxPooling1D()(x)\n",
    "  lstm_feats = Dense(32, activation=\"relu\")(x)\n",
    "  \n",
    "\n",
    "  naive_feats = Dense(64, activation=\"relu\")(dense_inputs)\n",
    "  \n",
    "  conc = Concatenate()([lstm_feats,naive_feats])\n",
    "\n",
    "  outputs = Dense(1, activation=\"sigmoid\")(conc)\n",
    "\n",
    "  return Model(inputs=[lstm_inputs,dense_inputs], outputs=outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2QI-SvbLE9g5",
    "outputId": "9525dac7-879f-4af2-9455-5f45fc8c0bde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8266/8266 [==============================] - 127s 15ms/step - loss: 0.1204 - accuracy: 0.9529 - val_loss: 0.1050 - val_accuracy: 0.9581\n",
      "Epoch 2/10\n",
      "8266/8266 [==============================] - 124s 15ms/step - loss: 0.1077 - accuracy: 0.9573 - val_loss: 0.1018 - val_accuracy: 0.9592\n",
      "Epoch 3/10\n",
      "8266/8266 [==============================] - 124s 15ms/step - loss: 0.1026 - accuracy: 0.9591 - val_loss: 0.0999 - val_accuracy: 0.9594\n",
      "Epoch 4/10\n",
      "8266/8266 [==============================] - 124s 15ms/step - loss: 0.0986 - accuracy: 0.9605 - val_loss: 0.0979 - val_accuracy: 0.9602\n",
      "Epoch 5/10\n",
      "8266/8266 [==============================] - 128s 16ms/step - loss: 0.0957 - accuracy: 0.9616 - val_loss: 0.0989 - val_accuracy: 0.9606\n",
      "Epoch 6/10\n",
      "8266/8266 [==============================] - 129s 16ms/step - loss: 0.0929 - accuracy: 0.9627 - val_loss: 0.0976 - val_accuracy: 0.9603\n",
      "Epoch 7/10\n",
      "8266/8266 [==============================] - 129s 16ms/step - loss: 0.0907 - accuracy: 0.9634 - val_loss: 0.0984 - val_accuracy: 0.9605\n",
      "Epoch 8/10\n",
      "8266/8266 [==============================] - 129s 16ms/step - loss: 0.0888 - accuracy: 0.9642 - val_loss: 0.0979 - val_accuracy: 0.9602\n",
      "Epoch 9/10\n",
      "8266/8266 [==============================] - 124s 15ms/step - loss: 0.0869 - accuracy: 0.9648 - val_loss: 0.0997 - val_accuracy: 0.9602\n",
      "Epoch 10/10\n",
      "8266/8266 [==============================] - 125s 15ms/step - loss: 0.0850 - accuracy: 0.9655 - val_loss: 0.0990 - val_accuracy: 0.9602\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6a4ae6a210>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training the model\n",
    "model = get_naive_model4(0.5)\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(decay = 0.00001),loss = tf.keras.losses.BinaryCrossentropy(),metrics=['accuracy'] )\n",
    "model.fit({'lstm_inputs':train,'dense_inputs':train_stats_merge}, y_train.values,batch_size = 128, epochs=10, verbose=1, validation_data=({'lstm_inputs':cv,'dense_inputs':cv_stats_merge}, y_cv.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1yqjwpaIIsv7",
    "outputId": "d4c755a3-66f9-4626-cf49-08f9dfc0d383"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 0\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "8266/8266 [==============================] - ETA: 0s - loss: 0.1205 - accuracy: 0.9527\n",
      "Epoch 1: val_loss improved from inf to 0.10799, saving model to naive_model_0_ind.hdf5\n",
      "8266/8266 [==============================] - 141s 16ms/step - loss: 0.1205 - accuracy: 0.9527 - val_loss: 0.1080 - val_accuracy: 0.9565\n",
      "Epoch 2/10\n",
      "8263/8266 [============================>.] - ETA: 0s - loss: 0.1078 - accuracy: 0.9574\n",
      "Epoch 2: val_loss improved from 0.10799 to 0.10287, saving model to naive_model_0_ind.hdf5\n",
      "8266/8266 [==============================] - 130s 16ms/step - loss: 0.1078 - accuracy: 0.9574 - val_loss: 0.1029 - val_accuracy: 0.9584\n",
      "Epoch 3/10\n",
      "8265/8266 [============================>.] - ETA: 0s - loss: 0.1029 - accuracy: 0.9590\n",
      "Epoch 3: val_loss improved from 0.10287 to 0.10134, saving model to naive_model_0_ind.hdf5\n",
      "8266/8266 [==============================] - 126s 15ms/step - loss: 0.1029 - accuracy: 0.9590 - val_loss: 0.1013 - val_accuracy: 0.9584\n",
      "Epoch 4/10\n",
      "8263/8266 [============================>.] - ETA: 0s - loss: 0.0998 - accuracy: 0.9601\n",
      "Epoch 4: val_loss improved from 0.10134 to 0.10015, saving model to naive_model_0_ind.hdf5\n",
      "8266/8266 [==============================] - 130s 16ms/step - loss: 0.0998 - accuracy: 0.9601 - val_loss: 0.1001 - val_accuracy: 0.9594\n",
      "Epoch 5/10\n",
      "8266/8266 [==============================] - ETA: 0s - loss: 0.0970 - accuracy: 0.9611\n",
      "Epoch 5: val_loss did not improve from 0.10015\n",
      "8266/8266 [==============================] - 129s 16ms/step - loss: 0.0970 - accuracy: 0.9611 - val_loss: 0.1004 - val_accuracy: 0.9589\n",
      "Epoch 6/10\n",
      "8263/8266 [============================>.] - ETA: 0s - loss: 0.0953 - accuracy: 0.9619\n",
      "Epoch 6: val_loss did not improve from 0.10015\n",
      "8266/8266 [==============================] - 125s 15ms/step - loss: 0.0953 - accuracy: 0.9619 - val_loss: 0.1013 - val_accuracy: 0.9587\n",
      "Epoch 7/10\n",
      "8265/8266 [============================>.] - ETA: 0s - loss: 0.0933 - accuracy: 0.9625\n",
      "Epoch 7: val_loss did not improve from 0.10015\n",
      "8266/8266 [==============================] - 129s 16ms/step - loss: 0.0933 - accuracy: 0.9625 - val_loss: 0.1003 - val_accuracy: 0.9591\n",
      "Epoch 8/10\n",
      "8264/8266 [============================>.] - ETA: 0s - loss: 0.0919 - accuracy: 0.9630\n",
      "Epoch 8: val_loss did not improve from 0.10015\n",
      "8266/8266 [==============================] - 129s 16ms/step - loss: 0.0919 - accuracy: 0.9630 - val_loss: 0.1033 - val_accuracy: 0.9577\n",
      "Epoch 9/10\n",
      "8266/8266 [==============================] - ETA: 0s - loss: 0.0906 - accuracy: 0.9634\n",
      "Epoch 9: val_loss did not improve from 0.10015\n",
      "8266/8266 [==============================] - 125s 15ms/step - loss: 0.0906 - accuracy: 0.9634 - val_loss: 0.1008 - val_accuracy: 0.9590\n",
      "Epoch 10/10\n",
      "8266/8266 [==============================] - ETA: 0s - loss: 0.0895 - accuracy: 0.9639\n",
      "Epoch 10: val_loss did not improve from 0.10015\n",
      "8266/8266 [==============================] - 125s 15ms/step - loss: 0.0895 - accuracy: 0.9639 - val_loss: 0.1012 - val_accuracy: 0.9587\n",
      "index: 1\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "8265/8266 [============================>.] - ETA: 0s - loss: 0.1204 - accuracy: 0.9529\n",
      "Epoch 1: val_loss improved from inf to 0.10668, saving model to naive_model_1_ind.hdf5\n",
      "8266/8266 [==============================] - 132s 16ms/step - loss: 0.1204 - accuracy: 0.9529 - val_loss: 0.1067 - val_accuracy: 0.9573\n",
      "Epoch 2/10\n",
      "8266/8266 [==============================] - ETA: 0s - loss: 0.1076 - accuracy: 0.9574\n",
      "Epoch 2: val_loss improved from 0.10668 to 0.10303, saving model to naive_model_1_ind.hdf5\n",
      "8266/8266 [==============================] - 131s 16ms/step - loss: 0.1076 - accuracy: 0.9574 - val_loss: 0.1030 - val_accuracy: 0.9584\n",
      "Epoch 3/10\n",
      "8266/8266 [==============================] - ETA: 0s - loss: 0.1028 - accuracy: 0.9589\n",
      "Epoch 3: val_loss improved from 0.10303 to 0.10271, saving model to naive_model_1_ind.hdf5\n",
      "8266/8266 [==============================] - 131s 16ms/step - loss: 0.1028 - accuracy: 0.9589 - val_loss: 0.1027 - val_accuracy: 0.9578\n",
      "Epoch 4/10\n",
      "8266/8266 [==============================] - ETA: 0s - loss: 0.0996 - accuracy: 0.9602\n",
      "Epoch 4: val_loss did not improve from 0.10271\n",
      "8266/8266 [==============================] - 125s 15ms/step - loss: 0.0996 - accuracy: 0.9602 - val_loss: 0.1035 - val_accuracy: 0.9578\n",
      "Epoch 5/10\n",
      "8264/8266 [============================>.] - ETA: 0s - loss: 0.0970 - accuracy: 0.9612\n",
      "Epoch 5: val_loss improved from 0.10271 to 0.10241, saving model to naive_model_1_ind.hdf5\n",
      "8266/8266 [==============================] - 125s 15ms/step - loss: 0.0970 - accuracy: 0.9612 - val_loss: 0.1024 - val_accuracy: 0.9583\n",
      "Epoch 6/10\n",
      "8264/8266 [============================>.] - ETA: 0s - loss: 0.0947 - accuracy: 0.9619\n",
      "Epoch 6: val_loss did not improve from 0.10241\n",
      "8266/8266 [==============================] - 130s 16ms/step - loss: 0.0947 - accuracy: 0.9619 - val_loss: 0.1028 - val_accuracy: 0.9582\n",
      "Epoch 7/10\n",
      "8266/8266 [==============================] - ETA: 0s - loss: 0.0931 - accuracy: 0.9624\n",
      "Epoch 7: val_loss improved from 0.10241 to 0.10196, saving model to naive_model_1_ind.hdf5\n",
      "8266/8266 [==============================] - 127s 15ms/step - loss: 0.0931 - accuracy: 0.9624 - val_loss: 0.1020 - val_accuracy: 0.9580\n",
      "Epoch 8/10\n",
      "8263/8266 [============================>.] - ETA: 0s - loss: 0.0921 - accuracy: 0.9631\n",
      "Epoch 8: val_loss improved from 0.10196 to 0.10158, saving model to naive_model_1_ind.hdf5\n",
      "8266/8266 [==============================] - 126s 15ms/step - loss: 0.0921 - accuracy: 0.9631 - val_loss: 0.1016 - val_accuracy: 0.9585\n",
      "Epoch 9/10\n",
      "8263/8266 [============================>.] - ETA: 0s - loss: 0.0904 - accuracy: 0.9635\n",
      "Epoch 9: val_loss improved from 0.10158 to 0.10141, saving model to naive_model_1_ind.hdf5\n",
      "8266/8266 [==============================] - 131s 16ms/step - loss: 0.0904 - accuracy: 0.9635 - val_loss: 0.1014 - val_accuracy: 0.9595\n",
      "Epoch 10/10\n",
      "8265/8266 [============================>.] - ETA: 0s - loss: 0.0893 - accuracy: 0.9641\n",
      "Epoch 10: val_loss did not improve from 0.10141\n",
      "8266/8266 [==============================] - 130s 16ms/step - loss: 0.0893 - accuracy: 0.9641 - val_loss: 0.1032 - val_accuracy: 0.9576\n",
      "index: 2\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "8264/8266 [============================>.] - ETA: 0s - loss: 0.1204 - accuracy: 0.9527\n",
      "Epoch 1: val_loss improved from inf to 0.10800, saving model to naive_model_2_ind.hdf5\n",
      "8266/8266 [==============================] - 134s 16ms/step - loss: 0.1204 - accuracy: 0.9527 - val_loss: 0.1080 - val_accuracy: 0.9568\n",
      "Epoch 2/10\n",
      "8266/8266 [==============================] - ETA: 0s - loss: 0.1079 - accuracy: 0.9572\n",
      "Epoch 2: val_loss improved from 0.10800 to 0.10326, saving model to naive_model_2_ind.hdf5\n",
      "8266/8266 [==============================] - 131s 16ms/step - loss: 0.1079 - accuracy: 0.9572 - val_loss: 0.1033 - val_accuracy: 0.9584\n",
      "Epoch 3/10\n",
      "8265/8266 [============================>.] - ETA: 0s - loss: 0.1031 - accuracy: 0.9589\n",
      "Epoch 3: val_loss improved from 0.10326 to 0.10245, saving model to naive_model_2_ind.hdf5\n",
      "8266/8266 [==============================] - 128s 15ms/step - loss: 0.1031 - accuracy: 0.9589 - val_loss: 0.1024 - val_accuracy: 0.9593\n",
      "Epoch 4/10\n",
      "8265/8266 [============================>.] - ETA: 0s - loss: 0.0999 - accuracy: 0.9599\n",
      "Epoch 4: val_loss improved from 0.10245 to 0.10044, saving model to naive_model_2_ind.hdf5\n",
      "8266/8266 [==============================] - 131s 16ms/step - loss: 0.0999 - accuracy: 0.9599 - val_loss: 0.1004 - val_accuracy: 0.9588\n",
      "Epoch 5/10\n",
      "8263/8266 [============================>.] - ETA: 0s - loss: 0.0971 - accuracy: 0.9611\n",
      "Epoch 5: val_loss improved from 0.10044 to 0.09939, saving model to naive_model_2_ind.hdf5\n",
      "8266/8266 [==============================] - 126s 15ms/step - loss: 0.0971 - accuracy: 0.9611 - val_loss: 0.0994 - val_accuracy: 0.9596\n",
      "Epoch 6/10\n",
      "8266/8266 [==============================] - ETA: 0s - loss: 0.0950 - accuracy: 0.9617\n",
      "Epoch 6: val_loss did not improve from 0.09939\n",
      "8266/8266 [==============================] - 129s 16ms/step - loss: 0.0950 - accuracy: 0.9617 - val_loss: 0.1024 - val_accuracy: 0.9583\n",
      "Epoch 7/10\n",
      "8266/8266 [==============================] - ETA: 0s - loss: 0.0935 - accuracy: 0.9622\n",
      "Epoch 7: val_loss did not improve from 0.09939\n",
      "8266/8266 [==============================] - 125s 15ms/step - loss: 0.0935 - accuracy: 0.9622 - val_loss: 0.0998 - val_accuracy: 0.9594\n",
      "Epoch 8/10\n",
      "8265/8266 [============================>.] - ETA: 0s - loss: 0.0920 - accuracy: 0.9629\n",
      "Epoch 8: val_loss improved from 0.09939 to 0.09930, saving model to naive_model_2_ind.hdf5\n",
      "8266/8266 [==============================] - 130s 16ms/step - loss: 0.0921 - accuracy: 0.9629 - val_loss: 0.0993 - val_accuracy: 0.9595\n",
      "Epoch 9/10\n",
      "8266/8266 [==============================] - ETA: 0s - loss: 0.0908 - accuracy: 0.9634\n",
      "Epoch 9: val_loss did not improve from 0.09930\n",
      "8266/8266 [==============================] - 125s 15ms/step - loss: 0.0908 - accuracy: 0.9634 - val_loss: 0.0998 - val_accuracy: 0.9595\n",
      "Epoch 10/10\n",
      "8266/8266 [==============================] - ETA: 0s - loss: 0.0897 - accuracy: 0.9638\n",
      "Epoch 10: val_loss did not improve from 0.09930\n",
      "8266/8266 [==============================] - 129s 16ms/step - loss: 0.0897 - accuracy: 0.9638 - val_loss: 0.1025 - val_accuracy: 0.9576\n",
      "index: 3\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "8265/8266 [============================>.] - ETA: 0s - loss: 0.1203 - accuracy: 0.9529\n",
      "Epoch 1: val_loss improved from inf to 0.10707, saving model to naive_model_3_ind.hdf5\n",
      "8266/8266 [==============================] - 132s 16ms/step - loss: 0.1203 - accuracy: 0.9529 - val_loss: 0.1071 - val_accuracy: 0.9572\n",
      "Epoch 2/10\n",
      "8265/8266 [============================>.] - ETA: 0s - loss: 0.1080 - accuracy: 0.9572\n",
      "Epoch 2: val_loss improved from 0.10707 to 0.10346, saving model to naive_model_3_ind.hdf5\n",
      "8266/8266 [==============================] - 126s 15ms/step - loss: 0.1080 - accuracy: 0.9572 - val_loss: 0.1035 - val_accuracy: 0.9586\n",
      "Epoch 3/10\n",
      "8266/8266 [==============================] - ETA: 0s - loss: 0.1030 - accuracy: 0.9589\n",
      "Epoch 3: val_loss improved from 0.10346 to 0.10118, saving model to naive_model_3_ind.hdf5\n",
      "8266/8266 [==============================] - 131s 16ms/step - loss: 0.1030 - accuracy: 0.9589 - val_loss: 0.1012 - val_accuracy: 0.9590\n",
      "Epoch 4/10\n",
      "8265/8266 [============================>.] - ETA: 0s - loss: 0.0999 - accuracy: 0.9601\n",
      "Epoch 4: val_loss improved from 0.10118 to 0.10107, saving model to naive_model_3_ind.hdf5\n",
      "8266/8266 [==============================] - 126s 15ms/step - loss: 0.0999 - accuracy: 0.9601 - val_loss: 0.1011 - val_accuracy: 0.9591\n",
      "Epoch 5/10\n",
      "8265/8266 [============================>.] - ETA: 0s - loss: 0.0974 - accuracy: 0.9611\n",
      "Epoch 5: val_loss improved from 0.10107 to 0.10080, saving model to naive_model_3_ind.hdf5\n",
      "8266/8266 [==============================] - 131s 16ms/step - loss: 0.0974 - accuracy: 0.9611 - val_loss: 0.1008 - val_accuracy: 0.9590\n",
      "Epoch 6/10\n",
      "8264/8266 [============================>.] - ETA: 0s - loss: 0.0951 - accuracy: 0.9618\n",
      "Epoch 6: val_loss did not improve from 0.10080\n",
      "8266/8266 [==============================] - 125s 15ms/step - loss: 0.0951 - accuracy: 0.9618 - val_loss: 0.1011 - val_accuracy: 0.9596\n",
      "Epoch 7/10\n",
      "8266/8266 [==============================] - ETA: 0s - loss: 0.0938 - accuracy: 0.9621\n",
      "Epoch 7: val_loss did not improve from 0.10080\n",
      "8266/8266 [==============================] - 125s 15ms/step - loss: 0.0938 - accuracy: 0.9621 - val_loss: 0.1008 - val_accuracy: 0.9588\n",
      "Epoch 8/10\n",
      "8265/8266 [============================>.] - ETA: 0s - loss: 0.0921 - accuracy: 0.9629\n",
      "Epoch 8: val_loss improved from 0.10080 to 0.10065, saving model to naive_model_3_ind.hdf5\n",
      "8266/8266 [==============================] - 126s 15ms/step - loss: 0.0921 - accuracy: 0.9629 - val_loss: 0.1006 - val_accuracy: 0.9590\n",
      "Epoch 9/10\n",
      "8263/8266 [============================>.] - ETA: 0s - loss: 0.0909 - accuracy: 0.9635\n",
      "Epoch 9: val_loss did not improve from 0.10065\n",
      "8266/8266 [==============================] - 130s 16ms/step - loss: 0.0909 - accuracy: 0.9635 - val_loss: 0.1019 - val_accuracy: 0.9583\n",
      "Epoch 10/10\n",
      "8263/8266 [============================>.] - ETA: 0s - loss: 0.0901 - accuracy: 0.9636\n",
      "Epoch 10: val_loss did not improve from 0.10065\n",
      "8266/8266 [==============================] - 125s 15ms/step - loss: 0.0901 - accuracy: 0.9636 - val_loss: 0.1007 - val_accuracy: 0.9591\n",
      "index: 4\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "8263/8266 [============================>.] - ETA: 0s - loss: 0.1204 - accuracy: 0.9528\n",
      "Epoch 1: val_loss improved from inf to 0.10654, saving model to naive_model_4_ind.hdf5\n",
      "8266/8266 [==============================] - 128s 15ms/step - loss: 0.1204 - accuracy: 0.9528 - val_loss: 0.1065 - val_accuracy: 0.9570\n",
      "Epoch 2/10\n",
      "8265/8266 [============================>.] - ETA: 0s - loss: 0.1075 - accuracy: 0.9575\n",
      "Epoch 2: val_loss improved from 0.10654 to 0.10353, saving model to naive_model_4_ind.hdf5\n",
      "8266/8266 [==============================] - 131s 16ms/step - loss: 0.1075 - accuracy: 0.9575 - val_loss: 0.1035 - val_accuracy: 0.9582\n",
      "Epoch 3/10\n",
      "8263/8266 [============================>.] - ETA: 0s - loss: 0.1030 - accuracy: 0.9589\n",
      "Epoch 3: val_loss improved from 0.10353 to 0.10217, saving model to naive_model_4_ind.hdf5\n",
      "8266/8266 [==============================] - 127s 15ms/step - loss: 0.1030 - accuracy: 0.9589 - val_loss: 0.1022 - val_accuracy: 0.9585\n",
      "Epoch 4/10\n",
      "8264/8266 [============================>.] - ETA: 0s - loss: 0.0996 - accuracy: 0.9602\n",
      "Epoch 4: val_loss improved from 0.10217 to 0.10182, saving model to naive_model_4_ind.hdf5\n",
      "8266/8266 [==============================] - 127s 15ms/step - loss: 0.0996 - accuracy: 0.9602 - val_loss: 0.1018 - val_accuracy: 0.9590\n",
      "Epoch 5/10\n",
      "8265/8266 [============================>.] - ETA: 0s - loss: 0.0972 - accuracy: 0.9611\n",
      "Epoch 5: val_loss improved from 0.10182 to 0.10057, saving model to naive_model_4_ind.hdf5\n",
      "8266/8266 [==============================] - 127s 15ms/step - loss: 0.0972 - accuracy: 0.9611 - val_loss: 0.1006 - val_accuracy: 0.9593\n",
      "Epoch 6/10\n",
      "8265/8266 [============================>.] - ETA: 0s - loss: 0.0952 - accuracy: 0.9619\n",
      "Epoch 6: val_loss did not improve from 0.10057\n",
      "8266/8266 [==============================] - 130s 16ms/step - loss: 0.0952 - accuracy: 0.9619 - val_loss: 0.1007 - val_accuracy: 0.9592\n",
      "Epoch 7/10\n",
      "8265/8266 [============================>.] - ETA: 0s - loss: 0.0935 - accuracy: 0.9624\n",
      "Epoch 7: val_loss did not improve from 0.10057\n",
      "8266/8266 [==============================] - 126s 15ms/step - loss: 0.0935 - accuracy: 0.9624 - val_loss: 0.1008 - val_accuracy: 0.9591\n",
      "Epoch 8/10\n",
      "8264/8266 [============================>.] - ETA: 0s - loss: 0.0920 - accuracy: 0.9631\n",
      "Epoch 8: val_loss did not improve from 0.10057\n",
      "8266/8266 [==============================] - 130s 16ms/step - loss: 0.0920 - accuracy: 0.9631 - val_loss: 0.1016 - val_accuracy: 0.9589\n",
      "Epoch 9/10\n",
      "8263/8266 [============================>.] - ETA: 0s - loss: 0.0909 - accuracy: 0.9633\n",
      "Epoch 9: val_loss did not improve from 0.10057\n",
      "8266/8266 [==============================] - 130s 16ms/step - loss: 0.0909 - accuracy: 0.9633 - val_loss: 0.1022 - val_accuracy: 0.9583\n",
      "Epoch 10/10\n",
      "8265/8266 [============================>.] - ETA: 0s - loss: 0.0897 - accuracy: 0.9637\n",
      "Epoch 10: val_loss did not improve from 0.10057\n",
      "8266/8266 [==============================] - 131s 16ms/step - loss: 0.0897 - accuracy: 0.9637 - val_loss: 0.1026 - val_accuracy: 0.9595\n",
      "Train F1 score at threshold 0.1 is 0.6510413108482361\n",
      "Test F1 score at threshold 0.1 is 0.6118343195266271\n",
      "--------------------------------------------------\n",
      "Train F1 score at threshold 0.11 is 0.6615215349523681\n",
      "Test F1 score at threshold 0.11 is 0.6198668626264373\n",
      "--------------------------------------------------\n",
      "Train F1 score at threshold 0.12 is 0.6713860236953332\n",
      "Test F1 score at threshold 0.12 is 0.6293274531422273\n",
      "--------------------------------------------------\n",
      "Train F1 score at threshold 0.13 is 0.6804687194989318\n",
      "Test F1 score at threshold 0.13 is 0.6367354276212306\n",
      "--------------------------------------------------\n",
      "Train F1 score at threshold 0.14 is 0.6881543667911865\n",
      "Test F1 score at threshold 0.14 is 0.6430856411662552\n",
      "--------------------------------------------------\n",
      "Train F1 score at threshold 0.15 is 0.6955795632543996\n",
      "Test F1 score at threshold 0.15 is 0.6484480118776969\n",
      "--------------------------------------------------\n",
      "Train F1 score at threshold 0.16 is 0.7022015003856131\n",
      "Test F1 score at threshold 0.16 is 0.6521739130434783\n",
      "--------------------------------------------------\n",
      "Train F1 score at threshold 0.17 is 0.7084807014425782\n",
      "Test F1 score at threshold 0.17 is 0.6566665074284622\n",
      "--------------------------------------------------\n",
      "Train F1 score at threshold 0.18 is 0.7141459432529608\n",
      "Test F1 score at threshold 0.18 is 0.6606010743841649\n",
      "--------------------------------------------------\n",
      "Train F1 score at threshold 0.19 is 0.7191084969861948\n",
      "Test F1 score at threshold 0.19 is 0.6641180218595304\n",
      "--------------------------------------------------\n",
      "Train F1 score at threshold 0.2 is 0.7237333989178553\n",
      "Test F1 score at threshold 0.2 is 0.6674937965260546\n",
      "--------------------------------------------------\n",
      "Train F1 score at threshold 0.21 is 0.7278699130348234\n",
      "Test F1 score at threshold 0.21 is 0.6710539535818346\n",
      "--------------------------------------------------\n",
      "Train F1 score at threshold 0.22 is 0.731616814671329\n",
      "Test F1 score at threshold 0.22 is 0.6730349067628678\n",
      "--------------------------------------------------\n",
      "Train F1 score at threshold 0.23 is 0.7350916337700479\n",
      "Test F1 score at threshold 0.23 is 0.6745501285347044\n",
      "--------------------------------------------------\n",
      "Train F1 score at threshold 0.24 is 0.7383342646652664\n",
      "Test F1 score at threshold 0.24 is 0.6766604205704767\n",
      "--------------------------------------------------\n",
      "Train F1 score at threshold 0.25 is 0.7410069142656999\n",
      "Test F1 score at threshold 0.25 is 0.6778022901565292\n",
      "--------------------------------------------------\n",
      "Train F1 score at threshold 0.26 is 0.743409547886798\n",
      "Test F1 score at threshold 0.26 is 0.6794136392606757\n",
      "--------------------------------------------------\n",
      "Train F1 score at threshold 0.27 is 0.7459731809886535\n",
      "Test F1 score at threshold 0.27 is 0.6807985403026725\n",
      "--------------------------------------------------\n",
      "Train F1 score at threshold 0.28 is 0.7479502318289469\n",
      "Test F1 score at threshold 0.28 is 0.6813698927061884\n",
      "--------------------------------------------------\n",
      "Train F1 score at threshold 0.29 is 0.7493689630801333\n",
      "Test F1 score at threshold 0.29 is 0.6842421922004048\n",
      "--------------------------------------------------\n",
      "Train F1 score at threshold 0.3 is 0.7509185620852888\n",
      "Test F1 score at threshold 0.3 is 0.6843006239991165\n",
      "--------------------------------------------------\n",
      "Train F1 score at threshold 0.31 is 0.7526330576360384\n",
      "Test F1 score at threshold 0.31 is 0.6839141343741288\n",
      "--------------------------------------------------\n",
      "Train F1 score at threshold 0.32 is 0.7540319514437601\n",
      "Test F1 score at threshold 0.32 is 0.684284509418049\n",
      "--------------------------------------------------\n",
      "Train F1 score at threshold 0.33 is 0.7550721606358503\n",
      "Test F1 score at threshold 0.33 is 0.6847838420515148\n",
      "--------------------------------------------------\n",
      "Train F1 score at threshold 0.34 is 0.7559881292282592\n",
      "Test F1 score at threshold 0.34 is 0.6841110793014601\n",
      "--------------------------------------------------\n",
      "Train F1 score at threshold 0.35 is 0.7565233422202053\n",
      "Test F1 score at threshold 0.35 is 0.6837755043061094\n",
      "--------------------------------------------------\n",
      "Train F1 score at threshold 0.36 is 0.7569476717167023\n",
      "Test F1 score at threshold 0.36 is 0.6842903828197946\n",
      "--------------------------------------------------\n",
      "Train F1 score at threshold 0.37 is 0.7570858369717143\n",
      "Test F1 score at threshold 0.37 is 0.6831135186057467\n",
      "--------------------------------------------------\n",
      "Train F1 score at threshold 0.38 is 0.7566468109835827\n",
      "Test F1 score at threshold 0.38 is 0.6823878823878824\n",
      "--------------------------------------------------\n",
      "Train F1 score at threshold 0.39 is 0.7563575620370574\n",
      "Test F1 score at threshold 0.39 is 0.6823656300557254\n",
      "--------------------------------------------------\n",
      "Train F1 score at threshold 0.4 is 0.7560548649427198\n",
      "Test F1 score at threshold 0.4 is 0.6820816227964259\n",
      "--------------------------------------------------\n",
      "Train F1 score at threshold 0.41 is 0.7551032562571653\n",
      "Test F1 score at threshold 0.41 is 0.681267871266046\n",
      "--------------------------------------------------\n",
      "Train F1 score at threshold 0.42 is 0.7546150382710491\n",
      "Test F1 score at threshold 0.42 is 0.6795186640471512\n",
      "--------------------------------------------------\n",
      "Train F1 score at threshold 0.43 is 0.7531280732279295\n",
      "Test F1 score at threshold 0.43 is 0.6773633998265395\n",
      "--------------------------------------------------\n",
      "Train F1 score at threshold 0.44 is 0.7515217159158518\n",
      "Test F1 score at threshold 0.44 is 0.6777840234838549\n",
      "--------------------------------------------------\n",
      "Train F1 score at threshold 0.45 is 0.7499346385125263\n",
      "Test F1 score at threshold 0.45 is 0.6757812499999999\n",
      "--------------------------------------------------\n",
      "Train F1 score at threshold 0.46 is 0.7480672151614078\n",
      "Test F1 score at threshold 0.46 is 0.6734032411820782\n",
      "--------------------------------------------------\n",
      "Train F1 score at threshold 0.47 is 0.7458104492325024\n",
      "Test F1 score at threshold 0.47 is 0.6717097249823707\n",
      "--------------------------------------------------\n",
      "Train F1 score at threshold 0.48 is 0.7436755306557248\n",
      "Test F1 score at threshold 0.48 is 0.6687799197826368\n",
      "--------------------------------------------------\n",
      "Train F1 score at threshold 0.49 is 0.7411597177473888\n",
      "Test F1 score at threshold 0.49 is 0.6649255680334292\n",
      "--------------------------------------------------\n",
      "Train F1 score at threshold 0.5 is 0.7386376406749185\n",
      "Test F1 score at threshold 0.5 is 0.661436012395332\n",
      "--------------------------------------------------\n",
      "CPU times: user 1h 53min 23s, sys: 5min 49s, total: 1h 59min 12s\n",
      "Wall time: 2h 4min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# simple ensemble model with same model trained 5 times on same data and y_pred = avg(5-model predictions) \n",
    "\n",
    "# arrays to save each model predictions \n",
    "train_predictions = np.empty((train.shape[0],5)) \n",
    "cv_predictions = np.empty((cv.shape[0],5))\n",
    "test_predictions = np.empty((test.shape[0],5))\n",
    "\n",
    "\n",
    "for ind in range(5):\n",
    "  print('index:', ind)\n",
    "  print('\\n')\n",
    "\n",
    "  #save epoch with minimum loss and use it for prediction\n",
    "  filepath=\"naive_model_\"+str(ind)+\"_ind.hdf5\"\n",
    "  checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "  callbacks_list = [checkpoint]\n",
    "\n",
    "  model = get_naive_model4(0.5)\n",
    "  model.compile(optimizer = 'adam',loss = tf.keras.losses.BinaryCrossentropy(),metrics=['accuracy'] )\n",
    "  model.fit({'lstm_inputs':train,'dense_inputs':train_probs}, y_train.values,batch_size = 128, epochs=10, verbose=1,\\\n",
    "            validation_data=({'lstm_inputs':cv,'dense_inputs':cv_probs}, y_cv.values),callbacks = [callbacks_list])\n",
    "  \n",
    "  #load best model saved\n",
    "  model.load_weights(filepath)\n",
    "\n",
    "  #append predictions of each model to prediction matrix\n",
    "  train_predictions[:,ind] = model.predict([train,train_probs]).ravel()\n",
    "  cv_predictions[:,ind] = model.predict([cv,cv_probs]).ravel()\n",
    "  test_predictions[:,ind] = model.predict([test,test_probs]).ravel()\n",
    "  \n",
    "  del model\n",
    "  gc.collect()\n",
    "\n",
    "\n",
    "# averaging all model predictions\n",
    "avg_preds_train = np.mean(train_predictions,axis = 1)\n",
    "avg_preds_cv = np.mean(cv_predictions,axis = 1)\n",
    "avg_preds_test = np.mean(test_predictions,axis = 1)\n",
    "\n",
    "#choose best threshold to evaluate the model\n",
    "\n",
    "thresholds = np.arange(0.1, 0.501, 0.01)\n",
    "for thresh in thresholds:\n",
    "      thresh = np.round(thresh, 2)\n",
    "      print(\"Train F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(y_train,(avg_preds_train>thresh).astype(int))))\n",
    "      print(\"Test F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(y_cv,(avg_preds_cv>thresh).astype(int))))\n",
    "      print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kg-z8V_QZmtk",
    "outputId": "0aa4b686-f00a-4b59-9a1d-59a8be934844"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1-score: 0.6907787143036861\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98    110278\n",
      "           1       0.64      0.75      0.69      7273\n",
      "\n",
      "    accuracy                           0.96    117551\n",
      "   macro avg       0.81      0.86      0.83    117551\n",
      "weighted avg       0.96      0.96      0.96    117551\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report on test data\n",
    "print('Test F1-score:',metrics.f1_score(y_test,(avg_preds_test>0.33).astype(int)))\n",
    "\n",
    "y_pred_test = [1 if pred > 0.33 else 0 for pred in avg_preds_test]\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "id": "yW8PXlBPYjWK",
    "outputId": "a1900d0c-fcdf-43fa-9fce-7edbeb21b006"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qeQ0cCI_Xb34",
    "outputId": "ef812b88-2c7e-4547-fe32-6f636432ad54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4901\n",
      "\n",
      "\n",
      "True value: 1 ,Predicted value: 0\n",
      "QUESTION: how does a tony awards presenter getting a standing ovation for saying f k trump advance the cause of liberalism\n",
      "\n",
      "\n",
      "True value: 0 ,Predicted value: 1\n",
      "QUESTION: has the us population realised that the best school in the world is perhaps on the other side of the atlantic sea and no longer harvard\n",
      "\n",
      "\n",
      "True value: 1 ,Predicted value: 0\n",
      "QUESTION: how do i deal with a feminist teacher\n",
      "\n",
      "\n",
      "True value: 1 ,Predicted value: 0\n",
      "QUESTION: why do the alleged top most genius professional mathematicians usually take centuries to understand so many elementary matters in their own fields\n",
      "\n",
      "\n",
      "True value: 1 ,Predicted value: 0\n",
      "QUESTION: if women have sex during periods cause it pregnancy\n",
      "\n",
      "\n",
      "True value: 1 ,Predicted value: 0\n",
      "QUESTION: why do dentists like to kill wild animals\n",
      "\n",
      "\n",
      "True value: 1 ,Predicted value: 0\n",
      "QUESTION: did donald trump do parkland\n",
      "\n",
      "\n",
      "True value: 0 ,Predicted value: 1\n",
      "QUESTION: why do christians and muslims engage in conflicts about religion and religion supremacy\n",
      "\n",
      "\n",
      "True value: 0 ,Predicted value: 1\n",
      "QUESTION: why do so many american christians not follow the teachings of christ but quote the old testament to back up their prejudices\n",
      "\n",
      "\n",
      "True value: 0 ,Predicted value: 1\n",
      "QUESTION: why exactly are we the us favoring immigration from less educated more violent and poorer countries instead of countries like norway or japan\n",
      "\n",
      "\n",
      "True value: 1 ,Predicted value: 0\n",
      "QUESTION: should david hogg and emma gonzales be immediately appointed to the supreme court\n",
      "\n",
      "\n",
      "True value: 1 ,Predicted value: 0\n",
      "QUESTION: if america was not a country of freedom consistent with its constitutional rights why would it even try to defend freedom in the world\n",
      "\n",
      "\n",
      "True value: 0 ,Predicted value: 1\n",
      "QUESTION: at what point did god stop ordering people to kill their children\n",
      "\n",
      "\n",
      "True value: 1 ,Predicted value: 0\n",
      "QUESTION: how do you feel about people getting abortions because the child is going to be intersex or queer\n",
      "\n",
      "\n",
      "True value: 0 ,Predicted value: 1\n",
      "QUESTION: in senator schumer called for a military parade was he being insincere then\n",
      "\n",
      "\n",
      "True value: 0 ,Predicted value: 1\n",
      "QUESTION: do trans people ever kill themselves for reasons unrelated to their transness\n",
      "\n",
      "\n",
      "True value: 0 ,Predicted value: 1\n",
      "QUESTION: is the vulva the part of the vagina that babies come out of\n",
      "\n",
      "\n",
      "True value: 1 ,Predicted value: 0\n",
      "QUESTION: trump continues to color his hair and skin different people call it different colors blonde yellow orange what is the possibility that he thinks he is coloring his skin and hair the color gold\n",
      "\n",
      "\n",
      "True value: 0 ,Predicted value: 1\n",
      "QUESTION: i am a mature unassuming woman about to have an affair with a mature man will he most likely expect me to have sexy lingerie and a fancy brazilian prep\n",
      "\n",
      "\n",
      "True value: 0 ,Predicted value: 1\n",
      "QUESTION: if islam was curtailed in western countries how would crypto muslims act\n"
     ]
    }
   ],
   "source": [
    "# check model predictions on wrong classification\n",
    "wrong_pred_ind = []\n",
    "for ind in range(len(y_test)):\n",
    "  if y_pred_test[ind] != y_test.values[ind]:\n",
    "    wrong_pred_ind.append(ind)\n",
    "\n",
    "wrong_pred_ind = np.array(wrong_pred_ind)\n",
    "\n",
    "for ind in np.random.choice(wrong_pred_ind,20):\n",
    "  \n",
    "  print('\\n')\n",
    "\n",
    "  print('True value:',y_test.values[ind],',Predicted value:',y_pred_test[ind])\n",
    "  print('QUESTION:',X_test['question'].iloc[ind])\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BoPc7OoG1QbF"
   },
   "source": [
    "\n",
    "- There are some data points that were mislabeled, but the model appears to be performing well on the milabeled data. For example model predicted correct labels for the below milabeled datapoints,\n",
    "\n",
    ">True value: 0 ,Predicted value: 1\n",
    "\n",
    "> **QUESTION: why exactly are we the us favoring immigration from less educated more violent and poorer countries instead of countries like norway or japan**\n",
    "\n",
    "\n",
    "> **QUESTION: do trans people ever kill themselves for reasons unrelated to their transness**\n",
    "\n",
    "\n",
    "----------------\n",
    "\n",
    "- Model seems to have trouble recognizing insincere questions related to a particular individual or a crisis. For example consider the below examples,\n",
    "\n",
    "\n",
    "> **QUESTION: did donald trump do parkland**\n",
    "\n",
    "> True value: 1 ,Predicted value: 0\n",
    "\n",
    "> **QUESTION: should david hogg and emma gonzales be immediately appointed to the supreme court**\n",
    "\n",
    "> True value: 1 ,Predicted value: 0\n",
    "\n",
    "\n",
    "- From the above examples we can see that model is unable to recognize insincerity when questions are targeted towards an individual or a crisis, which is sensible because model doesn't have any prior knowledge of the individual or crisis.\n",
    "------------------------------------------------------\n",
    "\n",
    "- There are also some insincere questions where model was unable to capture the context of the question,\n",
    "\n",
    "\n",
    "> True value: 1 ,Predicted value: 0\n",
    "\n",
    "> **QUESTION: how do you feel about people getting abortions because the child is going to be intersex or queer**\n",
    "\n",
    "> True value: 1 ,Predicted value: 0\n",
    "\n",
    "> **QUESTION: if america was not a country of freedom consistent with its constitutional rights why would it even try to defend freedom in the world**\n",
    "\n",
    "- The above example are clearly insincere but the model was unable to predict these questions\n",
    "\n",
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ute-bP8qEz_m"
   },
   "outputs": [],
   "source": [
    "'''np.save('test_predictions',test_preds)\n",
    "X_test.to_csv('test_split.csv')\n",
    "np.save('y_true',y_test.values)'''\n",
    "\n",
    "test_preds = np.load('test_predictions.npy')\n",
    "X_test = pd.read_csv('test_split.csv')\n",
    "y_test = np.load('y_true.npy')\n",
    "\n",
    "test_y = np.array(y_test,dtype=np.float32)\n",
    "\n",
    "y_pred_test = [1 if pred > 0.34 else 0 for pred in test_preds]\n",
    "predictions_test = np.array(y_pred_test,dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l1sUclJg8_uf",
    "outputId": "8ee41aaf-033c-4b9e-8b29-cecacc8f9366"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4991\n",
      "112560\n"
     ]
    }
   ],
   "source": [
    "# calculate the loss on each datapoint\n",
    "\n",
    "losses = []\n",
    "\n",
    "for actual,pred in zip(test_y,test_preds):\n",
    "\n",
    "  loss = tf.keras.backend.binary_crossentropy(actual,pred)\n",
    "  losses.append(loss.numpy()[0])\n",
    "\n",
    "losses = np.array(losses)\n",
    "\n",
    "wrong_pred_ind = []\n",
    "for ind in range(len(y_test)):\n",
    "  if y_pred_test[ind] != y_test[ind]:\n",
    "    wrong_pred_ind.append(ind)\n",
    "\n",
    "correct_pred_ind = []\n",
    "for ind in range(len(y_test)):\n",
    "  if y_pred_test[ind] == y_test[ind]:\n",
    "    correct_pred_ind.append(ind)\n",
    "\n",
    "print(len(wrong_pred_ind))\n",
    "print(len(correct_pred_ind))\n",
    "\n",
    "wrong_pred_ind = np.array(wrong_pred_ind)\n",
    "correct_pred_ind = np.array(correct_pred_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "id": "_j6qP2xKHLiW",
    "outputId": "d0e80aef-62c8-4e10-acbe-c49d93975b24"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "sns.kdeplot(losses,color = 'blue')\n",
    "plt.title('Distibution plot of Log-loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "biJxf722XxvJ",
    "outputId": "f305f6af-7392-4c5d-98f9-b8fa30cae3eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentile values of losses:\n",
      "--------------------------------------------------\n",
      "0 %le: 0.0\n",
      "10 %le: 0.0\n",
      "20 %le: 0.0001\n",
      "30 %le: 0.0002\n",
      "40 %le: 0.0005\n",
      "50 %le: 0.0009\n",
      "60 %le: 0.0018\n",
      "70 %le: 0.0043\n",
      "80 %le: 0.0156\n",
      "90 %le: 0.1423\n",
      "100 %le: 10.3518\n"
     ]
    }
   ],
   "source": [
    "print('Percentile values of losses:')\n",
    "print('-'*50)\n",
    "for i in range(0,110,10):\n",
    "  print(i,'%le:',np.round(np.percentile(losses,i),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z1GWg7pLilV3"
   },
   "outputs": [],
   "source": [
    "best_loss = 0.0043\n",
    "avgLoss_start = 0.015\n",
    "avgLoss_end = 1\n",
    "worst_loss = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "csUia1fqe8WL",
    "outputId": "af309cee-dcad-4360-b954-8852568bbf4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 insincere questions when loss is less than 0.0043\n",
      "\n",
      "\n",
      "Among 82259 question with loss less than 0.0043 there are ' 0 ' no.of questions that were mislabeled.\n",
      "\n",
      "\n",
      "QUESTIONS WITH LEAST LOSS:\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "why infinity plays important role in mathematics\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "what is your favourite blockchain project and why\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "with two steerable webcams a computer and a two metre rule could i determine the distance of objects within a couple of kilometres\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "is there any lip lock scene in the harry potter series between ginevra weasley and lord voldemort\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "cover design that list songs on the cd\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "what is the process of iaf airmen training\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "are there any tips or techniques for using watercolour pencils\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "what patrol gloves does the nypd use\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "should i change my real name on my job application so i do not get discriminated\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "which sport is more dangerous in pain between rugby and boxing\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "what does tavit nisanyan think about the movie theshawshank redemption\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "how should a young employee plan their future career taking ageism against older workers in mind\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "what is the maximum age for the ground staff jobs\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "what impact does subsidies have in economy\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "is the relationship between value and price of real property a weak positive one\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "do routers have different speeds\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "what services does apple outsource\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "what was that old microsoft art studio where you could add d animated things and there were multiple versions of it\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "has anyone ever regretted doing mba from stanford\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "what is difference between tax assistant and tax inspector\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "what is the difference to my personal life living in an authoritarian ruled country vs one under totalitarianism\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "what would be the best method of leadership\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "why does distilled water have a different freezing point\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "he said that he would not be happy if we were together because he does not have the same feelings as me what should i do\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "how much does it cost to call an number on o\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "how angry can you be on a person who is insensible during serious problem discussion\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "can one wear yellow saphire and cats eye in the same finger\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "how much does a it assessment cost for a person non profit\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "what is an individual clothing record\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "how can i make a draft of my novel what is the process\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bestLoss_questions = X_test.iloc[np.where(losses<=best_loss)]['question'].head(30).values\n",
    "true_y = y_test[np.where(losses<=best_loss)]\n",
    "pred_y = predictions_test[np.where(losses<=best_loss)]\n",
    "\n",
    "print('There are',sum(true_y),'insincere questions when loss is less than',best_loss)\n",
    "print('\\n')\n",
    "\n",
    "count_correctLabels = sum([1 if true != pred else 0 for true,pred in zip(true_y,pred_y)])\n",
    "print('Among',len(true_y),'question with loss less than',best_loss,'there are \\'',count_correctLabels,'\\' no.of questions that were mislabeled.')\n",
    "print('\\n')\n",
    "\n",
    "print('Questions with least loss:'.upper())\n",
    "\n",
    "for question,actual,prediction in zip(bestLoss_questions,true_y[:30],pred_y[:30]):\n",
    "\n",
    "  print('-'*50)\n",
    "  print('\\n')\n",
    "  print('actual label:',actual,'\\t predicted label:',int(prediction))\n",
    "  print('\\n')\n",
    "  print(question)\n",
    "  print('\\n')\n",
    "  #print('-'*75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCIRLeoYh_OG"
   },
   "source": [
    "- All the questions with loss less than 0.0043 are sincere questions, there are only 3 insincere questions with loss less than equal to 0.0043.\n",
    "\n",
    "- No question was misclassified when the loss is 0.0043\n",
    "\n",
    "- This seems reasonalble due the large amount of data that we have for sincere questions and small amount of data for insincere questions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rkWu2H6gi-zd",
    "outputId": "40658af1-36cd-4821-8f84-19f6340b9cc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5164 insincere questions when loss is greater than 0.015 and less than 1\n",
      "\n",
      "\n",
      "Among 20467 question with loss greater than 0.015 and less than 1 there are ' 1779 ' no.of questions that were mislabeled.\n",
      "\n",
      "\n",
      "QUESTIONS WITH AVG LOSS:\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "what is pakistan getting by protecting hafiz saeed\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "how common is it for jewish men and palestinian women to date\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "was it right for me to miss my prom\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "will the second amendment ever be abolished\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 1\n",
      "\n",
      "\n",
      "why in the fuck would anyone vote for that fucking cunt\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "why are we so obsessed with aliens\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "is canada willing to open up and take the refugees and immigrants that the us and uk will not now if not why not\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "would you rather be educated or intelligent\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 1\n",
      "\n",
      "\n",
      "why are brazilians so negative about their own country brazil is certainly better off than many other nations and yet its people seem to complain more than people from poorer nations why\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "why do argentina and brazil hate each other\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "there are caste systems in india and many people believing that one own character can be judged based on one own caste do you think it is a good idea to add caste as a to be filled field in an application form is it not unprofessional\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "can a president self pardon by first pardoning the vp then resigning and then being pardoned by the vp\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "my hair used to be natually very light blonde and shimmery now it is a dull dirty blonde i never dyed my hair and do not plan to any advice to get back to my old hair color naturally\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "i hired a friend who turned out to be a bad lazy employee how do i fire her\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "why would a girl out of nowhere come running to me and give me a bible saying she wanted to share it with me\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "would anyone like to share their experience with prazosin for ptsd i have just surrendered and accepted this prescription in an effort to try and get some sleep without waking up repeatedly from night terrors and night paralysis i am a little nervous\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 1\n",
      "\n",
      "\n",
      "what would happen to australia if white people never settled in the country would australia be run by a bunch of backward aboriginal tribes and torres strait islanders like papua new guinea\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "why did you bully people\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "do danes and norwegians refer to liberals as a bit swedish\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "i do not want to kill myself i just want to disappear for awhile what should i do\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "what can i do since i was kept in the dark about my wife own mental status illness before marriage\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 1\n",
      "\n",
      "\n",
      "why indians are not good looking than their neighbors\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "what was it like for the german people to readjust to life and their culture after wwii\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "do psychopaths cry\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "why do people think intelligent design always mean god own design intelligence on it is own does not imply god does it\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "why did turkey react so aggressively against the ypg in syria\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 1\n",
      "\n",
      "\n",
      "why is the average us american so poorly schoolarized compared to the average european\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "why is khmer rouge called rouge in english\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 0\n",
      "\n",
      "\n",
      "what if quora bans quorans because their writing styles do not fit their goal for machine learning\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 1\n",
      "\n",
      "\n",
      "after the media is done shoving homosexuality and transsexualism down our throats will they start supporting incest between consenting adults\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avgLoss_questions = X_test.iloc[np.where((losses>=avgLoss_start)&(losses<=avgLoss_end))]['question'].head(30).values\n",
    "true_y = y_test[np.where((losses>=avgLoss_start)&(losses<=avgLoss_end))]\n",
    "pred_y = predictions_test[np.where((losses>=avgLoss_start)&(losses<=avgLoss_end))]\n",
    "print('There are',sum(true_y),'insincere questions when loss is greater than',avgLoss_start,'and less than',avgLoss_end)\n",
    "print('\\n')\n",
    "\n",
    "count_correctLabels = sum([1 if true != pred else 0 for true,pred in zip(true_y,pred_y)])\n",
    "print('Among',len(true_y),'question with loss greater than',avgLoss_start,'and less than',avgLoss_end,'there are \\'',count_correctLabels,'\\' no.of questions that were mislabeled.')\n",
    "print('\\n')\n",
    "\n",
    "print('Questions with avg loss:'.upper())\n",
    "\n",
    "for question,actual,prediction in zip(avgLoss_questions,true_y[:30],pred_y[:30]):\n",
    "  print('-'*50)\n",
    "  print('\\n')\n",
    "  print('actual label:',actual,'\\t predicted label:',int(prediction))\n",
    "  print('\\n')\n",
    "  print(question)\n",
    "  print('\\n')\n",
    "  #print('-'*75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DIWffjjgkwYa"
   },
   "source": [
    "- There are 20467 questions with loss between 0.0156 and 1 and 5164 among them are insincere questoins.\n",
    "\n",
    "- If we observe the questions with loss between 0.015 and 1, there are queit a few no.of questions that are mislabeled, questions are mostly mislabeled as sincere questions while they actually belong to insncere category.\n",
    "\n",
    "- Model also predicted these mislabeled insincere questions as sincere questions, this could be a reason for recall and precision not improving to a better value. Model was able to predict few mislabeled questions to their true class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F3qIXsYRkizm",
    "outputId": "7d96cd7b-def8-4c93-a285-d2776174383a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2078 insincere questions when loss is greater than 1.0\n",
      "\n",
      "\n",
      "Among 3333 question with loss greater than 1.0 there are ' 3212 ' no.of questions that were mislabeled.\n",
      "\n",
      "\n",
      "QUESTIONS WITH HIGH LOSS:\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "why infinity plays important role in mathematics\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "what is your favourite blockchain project and why\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "with two steerable webcams a computer and a two metre rule could i determine the distance of objects within a couple of kilometres\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "is there any lip lock scene in the harry potter series between ginevra weasley and lord voldemort\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "cover design that list songs on the cd\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "what is the process of iaf airmen training\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "are there any tips or techniques for using watercolour pencils\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "what patrol gloves does the nypd use\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "should i change my real name on my job application so i do not get discriminated\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "which sport is more dangerous in pain between rugby and boxing\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "what does tavit nisanyan think about the movie theshawshank redemption\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "how should a young employee plan their future career taking ageism against older workers in mind\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "what is the maximum age for the ground staff jobs\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "what impact does subsidies have in economy\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "is the relationship between value and price of real property a weak positive one\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "do routers have different speeds\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "what services does apple outsource\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "what was that old microsoft art studio where you could add d animated things and there were multiple versions of it\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "has anyone ever regretted doing mba from stanford\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "what is difference between tax assistant and tax inspector\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "what is the difference to my personal life living in an authoritarian ruled country vs one under totalitarianism\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "what would be the best method of leadership\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "why does distilled water have a different freezing point\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "he said that he would not be happy if we were together because he does not have the same feelings as me what should i do\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "how much does it cost to call an number on o\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "how angry can you be on a person who is insensible during serious problem discussion\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "can one wear yellow saphire and cats eye in the same finger\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "how much does a it assessment cost for a person non profit\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "what is an individual clothing record\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "how can i make a draft of my novel what is the process\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "worstLoss_questions = X_test.iloc[np.where(losses>=worst_loss)]['question'].head(30).values\n",
    "true_y = y_test[np.where(losses>=worst_loss)]\n",
    "pred_y = predictions_test[np.where(losses>=worst_loss)]\n",
    "print('There are',sum(true_y),'insincere questions when loss is greater than',worst_loss)\n",
    "print('\\n')\n",
    "\n",
    "count_correctLabels = sum([1 if true != pred else 0 for true,pred in zip(true_y,pred_y)])\n",
    "print('Among',len(true_y),'question with loss greater than',worst_loss,'there are \\'',count_correctLabels,'\\' no.of questions that were mislabeled.')\n",
    "print('\\n')\n",
    "\n",
    "print('Questions with high loss:'.upper())\n",
    "\n",
    "for question,actual,prediction in zip(bestLoss_questions,true_y[:30],pred_y[:30]):\n",
    "\n",
    "  print('-'*50)\n",
    "  print('\\n')\n",
    "  print('actual label:',actual,'\\t predicted label:',int(prediction))\n",
    "  print('\\n')\n",
    "  print(question)\n",
    "  print('\\n')\n",
    "  #print('-'*75)\n",
    "  7273"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DluybUTyu0_C"
   },
   "source": [
    "- There are 3333 questions that have loss greater than 1, almost all the questions that have loss greater than 1 are misclassified by the model.\n",
    "\n",
    "- Most of the questions that were misclassified are actually mislabeled, model seems to uderstand the semantics of the data because for most cases model is actually prediting correct class labels for mislabeled data, but mislabeling is a problem for the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "id": "U63xtV-J-UoV",
    "outputId": "79eda85f-e45c-49c6-ff71-8513a5294861"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "misclassified_quesLoss = losses[wrong_pred_ind]\n",
    "correctpredicted_quesLoss = losses[correct_pred_ind]\n",
    "\n",
    "plt.figure(figsize=(14,6))\n",
    "\n",
    "#plt.subplot(1,2,1)\n",
    "sns.kdeplot(correctpredicted_quesLoss,color = 'green',label = 'Correctly classified points')\n",
    "#plt.legend()\n",
    "\n",
    "#plt.subplot(1,2,2)\n",
    "sns.kdeplot(misclassified_quesLoss,color = 'red',label = 'Misclassified points')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Distribution plots of loss values',color = 'darkolivegreen',fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "id": "R3ra0L_iZTts",
    "outputId": "a2cb4c90-12a3-40bb-c777-a287f885df51"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "sns.kdeplot(correctpredicted_quesLoss,color = 'green',label = 'Correctly classified points')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.kdeplot(misclassified_quesLoss,color = 'red',label = 'Misclassified points')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Distribution plots of loss values',color = 'darkolivegreen',fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oj5z8O30-uEO",
    "outputId": "f2a5f599-0d94-4518-ef48-bb7f28b9b9d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "|Percentile values of correctly classified points:|\n",
      "--------------------------------------------------\n",
      "\t 0 %le: \t 0.0\n",
      "\t 10 %le: \t 0.0\n",
      "\t 20 %le: \t 0.0001\n",
      "\t 30 %le: \t 0.0002\n",
      "\t 40 %le: \t 0.0004\n",
      "\t 50 %le: \t 0.0008\n",
      "\t 60 %le: \t 0.0015\n",
      "\t 70 %le: \t 0.0032\n",
      "\t 80 %le: \t 0.0094\n",
      "\t 90 %le: \t 0.0536\n",
      "\t 100 %le: \t 1.0785\n",
      "\n",
      "\n",
      "----------------------------------------------\n",
      "|Percentile values of Misclassified points:|\n",
      "----------------------------------------------\n",
      "\t 0 %le: \t 0.4158\n",
      "\t 10 %le: \t 0.5245\n",
      "\t 20 %le: \t 0.6553\n",
      "\t 30 %le: \t 0.861\n",
      "\t 40 %le: \t 1.1035\n",
      "\t 50 %le: \t 1.2778\n",
      "\t 60 %le: \t 1.5064\n",
      "\t 70 %le: \t 1.8399\n",
      "\t 80 %le: \t 2.3663\n",
      "\t 90 %le: \t 3.3146\n",
      "\t 100 %le: \t 10.3518\n"
     ]
    }
   ],
   "source": [
    "print('-'*50)\n",
    "print('|Percentile values of correctly classified points:|')\n",
    "print('-'*50)\n",
    "for i in range(0,110,10):\n",
    "  print('\\t',i,'%le:','\\t',np.round(np.percentile(correctpredicted_quesLoss,i),4))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('-'*46)\n",
    "print('|Percentile values of Misclassified points:|')\n",
    "print('-'*46)\n",
    "for i in range(0,110,10):\n",
    "  print('\\t',i,'%le:','\\t',np.round(np.percentile(misclassified_quesLoss,i),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W_nkTAqg144l",
    "outputId": "14c704da-204b-43ce-d9d0-d372f9af8f89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 90 %le: \t 0.0536\n",
      "\t 91 %le: \t 0.0682\n",
      "\t 92 %le: \t 0.0878\n",
      "\t 93 %le: \t 0.112\n",
      "\t 94 %le: \t 0.1427\n",
      "\t 95 %le: \t 0.1799\n",
      "\t 96 %le: \t 0.2252\n",
      "\t 97 %le: \t 0.2862\n",
      "\t 98 %le: \t 0.3688\n",
      "\t 99 %le: \t 0.5588\n",
      "\t 100 %le: \t 1.0785\n"
     ]
    }
   ],
   "source": [
    "for i in range(90,101):\n",
    "  print('\\t',i,'%le:','\\t',np.round(np.percentile(correctpredicted_quesLoss,i),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G_vkCTbMEqOd"
   },
   "source": [
    "- As we can see from the distribution plots of the losses of misclassified points and correctly classified points there is small overlap between the distributions. \n",
    "\n",
    "- All the misclassified points have a loss greater than 0.41 while only 2% of correctly classified data has loss greater than 0.41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a1Ize5rz_GK2",
    "outputId": "147c040e-4361-4de9-ba20-732f75c72579"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MISCLASSIFIED QUESTIONS WITH LEAST LOSS:\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "is canada willing to open up and take the refugees and immigrants that the us and uk will not now if not why not\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "there are caste systems in india and many people believing that one own character can be judged based on one own caste do you think it is a good idea to add caste as a to be filled field in an application form is it not unprofessional\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "why do people ignore obvious facts in opposition to gun control what is with the sensational hate for guns\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "do girls deserve reservation in iits\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "why do muslims revere moses and jesus so much\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "where did the stereotype about russians being cold hearted come from\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "is bestiality immoral if the animal initiates first what are some arguments for against it\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "why does quora always favor questions that are unflattering or disrespectful to president trump and favorable to those bashing him\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "how can christians catholics believe in god when there is no proof other than the bible\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "michael wolff said in his new book that trump did not read or even skim material given to him and his staff considered trump only semi literate do you think that is accurate\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "there are children percent are girls hoelw many are boys\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "which religion official supports killing of the people who do not believe in their god\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "crimes and extreme intolerance for non muslims in your country how do you see pakistan move forward to become a more tolerant society\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "why are there bad perception about ghana women\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "is this just anti turkey fake news fleeing erdogan own crackdown turks find new home in greece\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "do us citizens or the democrat party seriously question the amount that is spent on defence\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "is hindutva against islam or indian muslims\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "why is it that pakistan is afraid of asking itself the hard questions on terrorism corruption economy etc\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "is there a political and cultural divide between believer jews and those who were born jews but are atheists or not particularly religious such as noam chomsky bernie sanders jon stewart or lev trotsky\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "why do some women say to their gay male friends hey girl in greeting them do not some gay men find it offensive that women say that\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "why is it when a woman says she is in love she is but when a man does he is always dismissed as being infatuated\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "do you think it is unethical for a man who is secretly gay to marry a woman\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "is it okay for a muslim to watch gay porn or have anal sex\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "are university of chicago students secretly jealous of northwestern students\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "why are putin volunteering to turn over the recordings of the discussion between sergej lavrov and donald trump\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "being a keralite do you think there is any real issue in kerala as the bjp propagates\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "how did brazil become such a sexually loose nation\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "do chineses love black people\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "i think that the best way to get rid of us militarism is to create a corporation that will hire the k subsection of american youth the military recruiters target do you agree\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "what do you mean by trump own insanity do you consider someone insane if they do not agree with you\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_loss = 1.0\n",
    "\n",
    "misclassified_minLoss = X_test.iloc[wrong_pred_ind[np.where(misclassified_quesLoss<1)]]['question'].head(30).values\n",
    "true_y = y_test[wrong_pred_ind[np.where(misclassified_quesLoss<1)]]\n",
    "pred_y = predictions_test[wrong_pred_ind[np.where(misclassified_quesLoss<1)]]\n",
    "\n",
    "print('Misclassified questions with least loss:'.upper())\n",
    "print('\\n')\n",
    "\n",
    "for question,actual,prediction in zip(misclassified_minLoss,true_y[:30],pred_y[:30]):\n",
    "\n",
    "  print('-'*50)\n",
    "  print('\\n')\n",
    "  print('actual label:',actual,'\\t predicted label:',int(prediction))\n",
    "  print('\\n')\n",
    "  print(question)\n",
    "  print('\\n')\n",
    "  #print('-'*75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fvGmH1AIL6AX"
   },
   "source": [
    "- The misclassified questions with least logloss(<1.0) have all labels predicted as 1. These questions are indeed insincere but were mislabeled as sincere, all these questions have been correctly identified by the model as insincere.\n",
    "\n",
    "- It appears that mislabeled insincere questions has least loss values among the misclassifieds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NYbgE_O8Ck6u",
    "outputId": "ceba42a4-e974-4467-f8e7-072f87046053"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MISCLASSIFIED QUESTIONS WITH MODERATE LOSS:\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "quora is an indian oriented website should i delete my account\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "since humans hunt and eat primates is eating primates considered cannibalism\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "why are many actors in fiction movies especially space related shown with weird features like one eye half open head walking disabled like burn like skin sores does not that concept go against evolution as we know it what is being conveyed\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "why are democrats outraged about the possibility of russian interference of elections but passively accept it when democratic leaders do it\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "why should child molesters be jailed when they did not do anything wrong\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "i am masturbating while checking a picture of my mother in law is this abnormal\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "why do american love war and weapon when jesus said love your enemy\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "what if some lunatic or idiot nuked the amazon from the face of the earth\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "why do so many libertarians still believe in the free market despite most of today own most prominent economists being against it\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "why are there such an abundance of stupid questions on quora are people inherently stupid\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "why does not my penis have a mushroom head\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "why is trump so obsessed with discrediting obama\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "what life event made you realize that college students are ignorant and naive\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "legit question why does the usa keep intervening in other countries affairs what gives them legitimacy to do this\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "can i drink poop or toilet water\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "do indians and pakistanis secretly like each other\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "why is the whole spay neuter thing equal the most responsible pet owner in many people own mind when you can prevent pregnancy in pets without mutilating your pet with no medical reason behind it spay neuter does not equal responsible in any way\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "why do conservatives hate homeless people so much\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "is the most grotesque religious event in history gaudiyas teaching hatred of siva to westerners\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "do men view women as other human beings\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "why are so many sexist laws in the usa allowed to exist against men when the civil rights act says not to discriminate based on sex\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "if gay people are less than percent of the world own population then how come they are so visible in the public sphere\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "is hate towards muslims real for no reasons\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "how can we ensure that the poor people from drought prone areas like north karnataka and telengana get contruction jobs in hyderabad bangalore and other parts of south india instead of hindi speaking north indians\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "why are filipinos obsessed with eurasian\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "are iranians ironically western friendly and want non theocratic government\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "why do indians quora moderator catogarize the question why does the us support and endorse the unsc resolution to let kashmir people have a better life though cpec as a generization question in quora\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "i took a dna test and i am only percent jewish does that not make me a qualified jew i always thought of myself as one i mean it is the biggest group i am other than european\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "how ordinary iranians feel about their government giving about a billion dollars annually to hizb ullah and other terrorist organizations\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "how rape came be reduced\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "misclassified_que_minLoss = X_test.iloc[wrong_pred_ind[np.where((misclassified_quesLoss> 1) & (misclassified_quesLoss < 2))]]['question'].head(30).values\n",
    "true_y = y_test[wrong_pred_ind[np.where((misclassified_quesLoss > 1) & (misclassified_quesLoss < 2))]]\n",
    "pred_y = predictions_test[wrong_pred_ind[np.where((misclassified_quesLoss > 1) & (misclassified_quesLoss < 2))]]\n",
    "\n",
    "print('Misclassified questions with moderate loss:'.upper())\n",
    "print('\\n')\n",
    "\n",
    "for question,actual,prediction in zip(misclassified_que_minLoss,true_y[:30],pred_y[:30]):\n",
    "  print('-'*50)\n",
    "  print('\\n')\n",
    "  print('actual label:',actual,'\\t predicted label:',int(prediction))\n",
    "  print('\\n')\n",
    "  print(question)\n",
    "  print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "buVJGErUI3Va"
   },
   "source": [
    "- Again mislabeled data appears to be a problem when observed the questions with moderate loss, there are many questons that were mislabeled and model seems to be classifiying them correctly.\n",
    "\n",
    "- There are some questions where model is predicting them wrongly as sincere while they are actually insincere, model was unable to capture the insncerity for few questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p3dPzriXDyCt",
    "outputId": "3ca0f845-0c47-4d7f-f85f-5e692ca03bd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MISCLASSIFIED QUESTIONS WITH HIGH LOSS:\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "has not god outlawed spoiling the neighbour including any tax usury inflation or speculation\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "why is swiggy such a fraud service the prices are marked up over the actual prices average delivery time is more than hours for a distance of kms even if you this distance you will not take more than mins\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "i told her you are ugly just like your mom she started crying why did she cry when i told her the truth i mean did not lie\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "who would win in a fight king kong or stay puft marshmallow man\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "are there any projects to try to turn around the terrible demographics in germany\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "do democrats think we could make education cheaper in the us by removing things that do not affect a student own lifetime earnings in the long run evolution etc\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "who is your favorite pop star in\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "do divorcees amputate their finger if they can not get the ring off\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "what is tennessee made of\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "is there any country worse than croatia\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "what does your country think of peruvians in case you have met or heard of them\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "can you do anything better than blaming the past governments for your own failures mr sambit patra\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "how did ryan gosling overcome his childhood autism\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "what are your opinions on sex change and if it actually changes their sex or simply gives them valid reason to indulge their fantasies\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "which country is better to immigrate to sweet new zealand or putrid america\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "does pauline hanson assume all muslims are terrorists and that she wants them all out of australians\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "why did steve jobs get cancer from eating fruit\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "how can i give a good blowie to a young white boy\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "does it bother you that iam the master of the universe the creator of all i live in illinois drive a honda and enjoy the tasty treats on the mic pick value meal at mcdonalds\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "what do foreigners like about americans\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "why do you pretend to be psychopathic\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "are you a closet closet\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "what is the difference between halala and rape\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "people call xiaomi own smartphones as gareebon ka iphone poor own iphone would they call mi tv as gareebon ka pvr poor own pvr\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "did espn alienate millions of viewers by mixing politics with sports\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "what is difference between sunni shia and ahamadiya sects of muslims in which countries which of the sects are dominant why ahamadiya sects is persecuted by other two sects\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "what is the sexual orientation where a man likes women but none of them like him back\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "thomas edison invented electricity how did he get the idea in the first place how did he know he invented electricity when there were no electric instruments to test if his project was successful or not\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "why does not britain take action against the scl company is it trying to play with other democracies to promote its own interests is britain really trying to illegally influence other countries\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "what is you think that i might read all the notifications in after i do my appeal in nd circuit court of appeals where i really have to start writing briefs cases do it tommorrow too much fun remembering souad pussy conquerin\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "is it a viable strategy to launch nuclear strikes immediately after assassinating the president to delay retaliation allowing time to neutralise second strike capabilities would surviving commanders i e submarines retaliate if there own no point\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "do midgets have night vison\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "why can not we legalise cannibalism in india when animal slaughter for human consumption is legal\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "should i get a statue of robert e lee for my yard\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "what are some low cost business ideas suitable for a new entrepreneur today\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "why do muslims seem unappreciative of the west allowing them to immigrate\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "what is the best way to increase the height of a kidney bean in one week\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "how is the president of canada\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "what are the health risks of eating your own herpes scabs\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "should the nepalese army throw away their guns and start running beauty parlors\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "how long can a human hide in the hills after being turned into a animal human hybrid via a lab accident\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "why is the poor north korea a well recognized international sovereignty country but the wealthy south korea and japan are not sovereignty states\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "is sham idrees married to froggy\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "why are not all the liberal elitist leaving like they promised when trump got elected are they all cowardly liars\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "how did dame tu cosita become the dictator of communist mexico\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "is india getting free money as alms from developed world\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "who own the greatest boy\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "quora has an answer for anything i can imagine i would like to come up with a very unique question i e a question that has not been asked answered what question has yet to be asked on quora or is this it\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "why most of the people around the world hate hindus instead of radical islamists\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "what is the tallest that an year old boy can be\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "what happened to men when did you all start talking about your feelings\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "why do today own youth think their vote is worth more than people that paid taxes for years and fought in a war\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "what do us americans think of coatians and slovenians\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "how are the donald trump own rallies being funded are they being paid for by the taxpayers\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "is africa really bad trump said it was\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "why muslims kill minorities when they are in majority\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "what do you think of chandrababu threatening to raise a no confidence motion against the nda\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "what is the best part of a woman\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "for those who have retrograde saturn in a natal chart how will the upcoming saturn retrograde be\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "am i have in full erection i read that this is below average is something wrong with me and how do i fix it\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "why all main religions started from arab world namely jewism christianity islam\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "how do i treat my mom the best possible way to die from radiotherapy\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "if nato came together and decided to fight terrorism all together starting today how long would it take to take out turkey\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "why should not we advocate for trump supporters to be forced to pay higher taxes since they elected a man who is wasting our tax payer money and trying to waste more of it on a wall for his own selfish ego\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "i took mg aspirin after drinking about beers and two shots in roughly hours am i ok\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "how do you defeat feminism in the western world\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "why are there no death threats against padmavati producers\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "where can i get elderly aunties for sex in chennai\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "hardik patel says he is fighting against the injustices meted out to his community what injustices is he talking about\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "is canibalism in china on the rise\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "if a girl hits me do i legally have the right to hit back\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "do white rhino having privilege over black rhino in rhino society\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "i find turkish men hot is it possible for me to import one to europe\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "do uber drivers run over their passengers\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "does the kinship between humans and bonobos explain why a lot of humans seem obsessed with sex\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "do you think that duncan hines betty crocker and pillsbury instant cakes are desserts for the low income fixed income class while pecan pies and cheesecakes are desserts for upper classes\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "how do people with low quality dna justify their existence\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "is it just me or is modern racism sexism and homophobia just a capitalist plot to divide the workers\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "why are guys into pussy\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "is it normal not to want to be a girl own father a girl gives a lot of work i would rather have a boy which gives less work is it normal\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "how cold hearted are the mcann when they sold maddie to a pedophile\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "can i contract cancer from listening to dua lipa i just saw her music video and i am pretty sure it gave me cancer in my eyes and ears\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "my parents will not let the kitten go inside\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "what would happen if khamenei suddenly died like a dog\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "where can i find the most beautiful women own dresses at a reasonable price\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "why does not the us try to influence the russian election\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "why is it that indian muslims boast of ruling india for a millenia denying evident destruction of temples killing of millions of local citizens yet keep crying that they are victimized\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "how do i find a well endowed male who will satisfy my girlfriend needs she is year own younger\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "how much value has the world lost to people fiddling on their linux desktops\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "why do people ask me questions on quora and then not even have the courtesy to upvote my answers when they are correct\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "where do we get date drug in chennai\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "will trump own deregulation strategy benefit the very rich or will strategy own very rich trump benefit the deregulation\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "what urged muhammad to encourage his daughter in law umm salama to divorce her husband and then marry him secretly\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "will i be hang myself to death if i do not get jobs after btech ee or if i get jobs and i will be immediately terminated\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "what makes you think that wwe and professional wrestling are the same thing professional wrestling died a long time ago with the real uwf\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "why does not anyone write a practical answer on quora\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 0 \t predicted label: 1\n",
      "\n",
      "\n",
      "why do americans say immigrants are stealing their jobs when as little as percent of americans hold a masters or any other professional degree\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "is the us a jewocracy or democracy\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "i am years old and i want to join iit am i too late how could i start studying\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "actual label: 1 \t predicted label: 0\n",
      "\n",
      "\n",
      "what is the difference between and a cow\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "misclassified_que_minLoss = X_test.iloc[wrong_pred_ind[np.where(misclassified_quesLoss>2)]]['question'].head(100).values\n",
    "true_y = y_test[wrong_pred_ind[np.where(misclassified_quesLoss>2)]]\n",
    "pred_y = predictions_test[wrong_pred_ind[np.where(misclassified_quesLoss>2)]]\n",
    "\n",
    "print('Misclassified questions with high loss:'.upper())\n",
    "print('\\n')\n",
    "\n",
    "for question,actual,prediction in zip(misclassified_que_minLoss,true_y[:100],pred_y[:100]):\n",
    "  print('-'*50)\n",
    "  print('\\n')\n",
    "  print('actual label:',actual,'\\t predicted label:',int(prediction))\n",
    "  print('\\n')\n",
    "  print(question)\n",
    "  print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MM8rPKbULAiP"
   },
   "source": [
    "- Most of the questions with losses grater than 2.0 are labeled as sincere, data mislabeling issue can be observed even for the loss greater than 2. \n",
    "\n",
    "- Model is miclassifying insincere questions as sincere,this could be because of the mislabeled data because if we observe the misclassified questions with loss less than 1 all of them are misclassified as sincere while they were actually insincere, even though model was able to predict them as insincere model appears to get confused between sincere and insincere questions because of mislabeling.\n",
    "\n",
    "- Molde performance might have been much better if there are no mislabeld data"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "QuoraInsincereCLF_models.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02a802ce1497423a81b25bbd7f4fca1c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0ad8e282bd69456aabb5ecc094b9e73d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b6a78ef596064e8a9e2dd3989ba98d33",
       "IPY_MODEL_b795cf161c8f467bb9745733b5d4910d",
       "IPY_MODEL_fe64bb601c5746f8a03097a12307d913"
      ],
      "layout": "IPY_MODEL_a15df77faee342ebb3e0368d6be1350c"
     }
    },
    "0ce161d64fef4e269468c61834ecfc77": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "253475ae5695466e921636ee5a47d40a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0ce161d64fef4e269468c61834ecfc77",
      "placeholder": "​",
      "style": "IPY_MODEL_5cc7ec1ae00e446bb2dd353df1544c94",
      "value": "Downloading config.json: 100%"
     }
    },
    "2bdae8063e1a42969dc79f838e5fee6e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3817362a79b7497ca98cf37be7ecb0d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3927e1162ef24f3caf54d23926dbd8eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4cbf8313d8a5434dafd6fbd7d27dd194": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d094b6ed00eb4e549402d59145305eb2",
      "placeholder": "​",
      "style": "IPY_MODEL_9eae9558a4d746bc9183be7d11bdb575",
      "value": " 455k/455k [00:01&lt;00:00, 519kB/s]"
     }
    },
    "4d53dc88b23a49379a4a0a7e173f3036": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "530ea6205a00418d8e6d4ed086405f21": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56cf30a6ad1745e88c54148c024b2cb1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5cc7ec1ae00e446bb2dd353df1544c94": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "62b7ead9024348c191c4c9c7a15511e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "62c645a3339144cfa85d0381cd5f2fc0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "63da75f767e943838c0e8855afd023b6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "65195953ded4455fa418c64b45943b0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "65ada4a2bf2e41f2b66e150442bc4a8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6c7e393d33574398a0929c9d546325d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c4b8d719a83b4415a3e23882b157efa2",
      "placeholder": "​",
      "style": "IPY_MODEL_d263f08f1bf44f7fb9ad3828388274ab",
      "value": "Downloading tokenizer_config.json: 100%"
     }
    },
    "77868c0b788241c28d9dd9c0907bf871": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_253475ae5695466e921636ee5a47d40a",
       "IPY_MODEL_dab064057adf4c72948a40c812897e87",
       "IPY_MODEL_eec4707001b640c59371c1cab546206b"
      ],
      "layout": "IPY_MODEL_de0845d10ad541c68c54b0d3c275f53b"
     }
    },
    "78e5cfb4edac4408bd1c9ef3b32c8a70": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a3d626c49f24b189c00757c62dced5c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_91148becc492492a8d2f51ae5a183e43",
       "IPY_MODEL_7aa3f812c4a44206895a793bbc1a4c55",
       "IPY_MODEL_b018b10235b44319b714c8ecb09c1d89"
      ],
      "layout": "IPY_MODEL_c9fa1715745d48a0bb51a048ccfe6fe2"
     }
    },
    "7aa3f812c4a44206895a793bbc1a4c55": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a3267242508540f1a79740358d5cb35c",
      "max": 363423424,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4d53dc88b23a49379a4a0a7e173f3036",
      "value": 363423424
     }
    },
    "824b36cbf756402294e1294a88dc50bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6c7e393d33574398a0929c9d546325d9",
       "IPY_MODEL_b883c588d7a7417b8c2fceded48ea5b7",
       "IPY_MODEL_d7bf0e5671b146ffa7fb3620ae14de71"
      ],
      "layout": "IPY_MODEL_d51029699eea4a5fa18e5dbb43284b2a"
     }
    },
    "866b002b1c394242a56c7abada15fb80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8f324b7d87d34129b7bdbba0f23cfd90": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8fe08ed80920415492b4f8a33115b71c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "91148becc492492a8d2f51ae5a183e43": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_97d33ecd88bc4dcfb31c70a957262283",
      "placeholder": "​",
      "style": "IPY_MODEL_8fe08ed80920415492b4f8a33115b71c",
      "value": "Downloading tf_model.h5: 100%"
     }
    },
    "95def20fb1454ab98dc8a6c05386d29a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "97d33ecd88bc4dcfb31c70a957262283": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9eae9558a4d746bc9183be7d11bdb575": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9fdb2cf3e20941fcb027d116bed00e89": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a15df77faee342ebb3e0368d6be1350c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a3267242508540f1a79740358d5cb35c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aeba60ea93bb4e3ab3e0bb7c2a79568d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b018b10235b44319b714c8ecb09c1d89": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2bdae8063e1a42969dc79f838e5fee6e",
      "placeholder": "​",
      "style": "IPY_MODEL_65ada4a2bf2e41f2b66e150442bc4a8d",
      "value": " 347M/347M [00:07&lt;00:00, 55.1MB/s]"
     }
    },
    "b6a78ef596064e8a9e2dd3989ba98d33": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_63da75f767e943838c0e8855afd023b6",
      "placeholder": "​",
      "style": "IPY_MODEL_aeba60ea93bb4e3ab3e0bb7c2a79568d",
      "value": "Downloading vocab.txt: 100%"
     }
    },
    "b795cf161c8f467bb9745733b5d4910d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd20f596f67e4d9ca2441e95292aeac7",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9fdb2cf3e20941fcb027d116bed00e89",
      "value": 231508
     }
    },
    "b883c588d7a7417b8c2fceded48ea5b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_530ea6205a00418d8e6d4ed086405f21",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3817362a79b7497ca98cf37be7ecb0d6",
      "value": 28
     }
    },
    "c4b8d719a83b4415a3e23882b157efa2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c63549f40aa7463aa6dea97813d00c96": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cc2b1495b81444f1bce8a23e4d8fbba7",
      "placeholder": "​",
      "style": "IPY_MODEL_62b7ead9024348c191c4c9c7a15511e1",
      "value": "Downloading tokenizer.json: 100%"
     }
    },
    "c9fa1715745d48a0bb51a048ccfe6fe2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cc2b1495b81444f1bce8a23e4d8fbba7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd20f596f67e4d9ca2441e95292aeac7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d094b6ed00eb4e549402d59145305eb2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d263f08f1bf44f7fb9ad3828388274ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d51029699eea4a5fa18e5dbb43284b2a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d7a26e8aa76449509bf958cea9fece70": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d7bf0e5671b146ffa7fb3620ae14de71": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d7a26e8aa76449509bf958cea9fece70",
      "placeholder": "​",
      "style": "IPY_MODEL_56cf30a6ad1745e88c54148c024b2cb1",
      "value": " 28.0/28.0 [00:00&lt;00:00, 794B/s]"
     }
    },
    "dab064057adf4c72948a40c812897e87": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_78e5cfb4edac4408bd1c9ef3b32c8a70",
      "max": 483,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e9fc86e389194da2a894abb049e6e261",
      "value": 483
     }
    },
    "db4370796ab8443a8f73e8f33fc87326": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c63549f40aa7463aa6dea97813d00c96",
       "IPY_MODEL_fb1f19d7cb394f24adb7c2dd1b0b9787",
       "IPY_MODEL_4cbf8313d8a5434dafd6fbd7d27dd194"
      ],
      "layout": "IPY_MODEL_02a802ce1497423a81b25bbd7f4fca1c"
     }
    },
    "de0845d10ad541c68c54b0d3c275f53b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e9fc86e389194da2a894abb049e6e261": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "eec4707001b640c59371c1cab546206b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_95def20fb1454ab98dc8a6c05386d29a",
      "placeholder": "​",
      "style": "IPY_MODEL_3927e1162ef24f3caf54d23926dbd8eb",
      "value": " 483/483 [00:00&lt;00:00, 3.69kB/s]"
     }
    },
    "fb1f19d7cb394f24adb7c2dd1b0b9787": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_62c645a3339144cfa85d0381cd5f2fc0",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_65195953ded4455fa418c64b45943b0a",
      "value": 466062
     }
    },
    "fe64bb601c5746f8a03097a12307d913": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8f324b7d87d34129b7bdbba0f23cfd90",
      "placeholder": "​",
      "style": "IPY_MODEL_866b002b1c394242a56c7abada15fb80",
      "value": " 226k/226k [00:00&lt;00:00, 260kB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
